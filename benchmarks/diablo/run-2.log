Number of nodes =  10
Number of executors =  49
myHadoop: Setting MH_IPOIB_TRANSFORM='s/\([^.]*\).*$/\1.ibnet/' from myhadoop.conf
myHadoop: Setting MH_SCRATCH_DIR=/scratch/$USER/$SLURM_JOBID from myhadoop.conf
myHadoop: Using HADOOP_HOME=/opt/hadoop/2.6.0
myHadoop: Using MH_SCRATCH_DIR=/scratch/fegaras/31371759
myHadoop: Using JAVA_HOME=/lib/jvm/java
myHadoop: Generating Hadoop configuration in directory in /home/fegaras/cometcluster...
myHadoop: Backing up old config dir to /home/fegaras/cometcluster.64...
‘/home/fegaras/cometcluster’ -> ‘/home/fegaras/cometcluster.64’
myHadoop: Designating comet-22-13.ibnet as master node (namenode, secondary namenode, and jobtracker)
myHadoop: The following nodes will be slaves (datanode, tasktracer):
comet-22-13.ibnet
comet-22-57.ibnet
comet-22-58.ibnet
comet-22-70.ibnet
comet-27-16.ibnet
comet-27-45.ibnet
comet-27-53.ibnet
comet-27-56.ibnet
comet-27-58.ibnet
comet-27-70.ibnet
20/02/06 10:32:41 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = comet-22-13.sdsc.edu/198.202.113.122
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 2.6.0
STARTUP_MSG:   classpath = /home/fegaras/cometcluster:/opt/hadoop/2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop/2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop/2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/opt/hadoop/2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/opt/hadoop/2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/opt/hadoop/2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/opt/hadoop/2.6.0/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by 'jenkins' on 2014-11-13T21:10Z
STARTUP_MSG:   java = 1.8.0_212
************************************************************/
20/02/06 10:32:41 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
20/02/06 10:32:41 INFO namenode.NameNode: createNameNode [-format]
20/02/06 10:32:42 WARN common.Util: Path /scratch/fegaras/31371759/namenode_data should be specified as a URI in configuration files. Please update hdfs configuration.
20/02/06 10:32:42 WARN common.Util: Path /scratch/fegaras/31371759/namenode_data should be specified as a URI in configuration files. Please update hdfs configuration.
Formatting using clusterid: CID-161fd3a1-aade-4350-8569-effaa99526e1
20/02/06 10:32:42 INFO namenode.FSNamesystem: No KeyProvider found.
20/02/06 10:32:42 INFO namenode.FSNamesystem: fsLock is fair:true
20/02/06 10:32:42 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
20/02/06 10:32:42 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
20/02/06 10:32:42 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
20/02/06 10:32:42 INFO blockmanagement.BlockManager: The block deletion will start around 2020 Feb 06 10:32:42
20/02/06 10:32:42 INFO util.GSet: Computing capacity for map BlocksMap
20/02/06 10:32:42 INFO util.GSet: VM type       = 64-bit
20/02/06 10:32:42 INFO util.GSet: 2.0% max memory 958.5 MB = 19.2 MB
20/02/06 10:32:42 INFO util.GSet: capacity      = 2^21 = 2097152 entries
20/02/06 10:32:42 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
20/02/06 10:32:42 INFO blockmanagement.BlockManager: defaultReplication         = 3
20/02/06 10:32:42 INFO blockmanagement.BlockManager: maxReplication             = 512
20/02/06 10:32:42 INFO blockmanagement.BlockManager: minReplication             = 1
20/02/06 10:32:42 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
20/02/06 10:32:42 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
20/02/06 10:32:42 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
20/02/06 10:32:42 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
20/02/06 10:32:42 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
20/02/06 10:32:42 INFO namenode.FSNamesystem: fsOwner             = fegaras (auth:SIMPLE)
20/02/06 10:32:42 INFO namenode.FSNamesystem: supergroup          = supergroup
20/02/06 10:32:42 INFO namenode.FSNamesystem: isPermissionEnabled = true
20/02/06 10:32:42 INFO namenode.FSNamesystem: HA Enabled: false
20/02/06 10:32:42 INFO namenode.FSNamesystem: Append Enabled: true
20/02/06 10:32:42 INFO util.GSet: Computing capacity for map INodeMap
20/02/06 10:32:42 INFO util.GSet: VM type       = 64-bit
20/02/06 10:32:42 INFO util.GSet: 1.0% max memory 958.5 MB = 9.6 MB
20/02/06 10:32:42 INFO util.GSet: capacity      = 2^20 = 1048576 entries
20/02/06 10:32:42 INFO namenode.NameNode: Caching file names occuring more than 10 times
20/02/06 10:32:42 INFO util.GSet: Computing capacity for map cachedBlocks
20/02/06 10:32:42 INFO util.GSet: VM type       = 64-bit
20/02/06 10:32:42 INFO util.GSet: 0.25% max memory 958.5 MB = 2.4 MB
20/02/06 10:32:42 INFO util.GSet: capacity      = 2^18 = 262144 entries
20/02/06 10:32:42 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
20/02/06 10:32:42 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
20/02/06 10:32:42 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
20/02/06 10:32:42 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
20/02/06 10:32:42 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
20/02/06 10:32:42 INFO util.GSet: Computing capacity for map NameNodeRetryCache
20/02/06 10:32:42 INFO util.GSet: VM type       = 64-bit
20/02/06 10:32:42 INFO util.GSet: 0.029999999329447746% max memory 958.5 MB = 294.5 KB
20/02/06 10:32:42 INFO util.GSet: capacity      = 2^15 = 32768 entries
20/02/06 10:32:42 INFO namenode.NNConf: ACLs enabled? false
20/02/06 10:32:42 INFO namenode.NNConf: XAttrs enabled? true
20/02/06 10:32:42 INFO namenode.NNConf: Maximum size of an xattr: 16384
20/02/06 10:32:42 INFO namenode.FSImage: Allocated new BlockPoolId: BP-669120096-198.202.113.122-1581013962538
20/02/06 10:32:42 INFO common.Storage: Storage directory /scratch/fegaras/31371759/namenode_data has been successfully formatted.
20/02/06 10:32:42 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
20/02/06 10:32:42 INFO util.ExitUtil: Exiting with status 0
20/02/06 10:32:42 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at comet-22-13.sdsc.edu/198.202.113.122
************************************************************/
myHadoop:  
myHadoop: Enabling experimental Spark support
myHadoop: Using SPARK_CONF_DIR=/home/fegaras/cometcluster/spark
myHadoop:  
To use Spark, you will want to type the following commands:"
  source /home/fegaras/cometcluster/spark/spark-env.sh
  myspark start
Starting namenodes on [comet-22-13.ibnet]
comet-22-13.ibnet: starting namenode, logging to /scratch/fegaras/31371759/logs/hadoop-fegaras-namenode-comet-22-13.sdsc.edu.out
comet-22-13.ibnet: starting datanode, logging to /scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-13.sdsc.edu.out
comet-27-45.ibnet: starting datanode, logging to /scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-45.sdsc.edu.out
comet-22-58.ibnet: starting datanode, logging to /scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-58.sdsc.edu.out
comet-27-58.ibnet: starting datanode, logging to /scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-58.sdsc.edu.out
comet-27-53.ibnet: starting datanode, logging to /scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-53.sdsc.edu.out
comet-27-70.ibnet: starting datanode, logging to /scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-70.sdsc.edu.out
comet-27-56.ibnet: starting datanode, logging to /scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-56.sdsc.edu.out
comet-27-16.ibnet: starting datanode, logging to /scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-16.sdsc.edu.out
comet-22-70.ibnet: starting datanode, logging to /scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-70.sdsc.edu.out
comet-22-57.ibnet: starting datanode, logging to /scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-57.sdsc.edu.out
Starting secondary namenodes [comet-22-13.ibnet]
comet-22-13.ibnet: starting secondarynamenode, logging to /scratch/fegaras/31371759/logs/hadoop-fegaras-secondarynamenode-comet-22-13.sdsc.edu.out
starting org.apache.spark.deploy.master.Master, logging to /scratch/fegaras/31371759/logs/spark-fegaras-org.apache.spark.deploy.master.Master-1-comet-22-13.out
comet-27-70.ibnet: starting org.apache.spark.deploy.worker.Worker, logging to /oasis/projects/nsf/uot143/fegaras/spark-2.2.0-bin-hadoop2.6/logs/spark-fegaras-org.apache.spark.deploy.worker.Worker-1-comet-27-70.sdsc.edu.out
comet-27-56.ibnet: starting org.apache.spark.deploy.worker.Worker, logging to /oasis/projects/nsf/uot143/fegaras/spark-2.2.0-bin-hadoop2.6/logs/spark-fegaras-org.apache.spark.deploy.worker.Worker-1-comet-27-56.sdsc.edu.out
comet-27-16.ibnet: starting org.apache.spark.deploy.worker.Worker, logging to /oasis/projects/nsf/uot143/fegaras/spark-2.2.0-bin-hadoop2.6/logs/spark-fegaras-org.apache.spark.deploy.worker.Worker-1-comet-27-16.sdsc.edu.out
comet-22-13.ibnet: starting org.apache.spark.deploy.worker.Worker, logging to /oasis/projects/nsf/uot143/fegaras/spark-2.2.0-bin-hadoop2.6/logs/spark-fegaras-org.apache.spark.deploy.worker.Worker-1-comet-22-13.sdsc.edu.out
comet-27-58.ibnet: starting org.apache.spark.deploy.worker.Worker, logging to /oasis/projects/nsf/uot143/fegaras/spark-2.2.0-bin-hadoop2.6/logs/spark-fegaras-org.apache.spark.deploy.worker.Worker-1-comet-27-58.sdsc.edu.out
comet-22-58.ibnet: starting org.apache.spark.deploy.worker.Worker, logging to /oasis/projects/nsf/uot143/fegaras/spark-2.2.0-bin-hadoop2.6/logs/spark-fegaras-org.apache.spark.deploy.worker.Worker-1-comet-22-58.sdsc.edu.out
comet-22-70.ibnet: starting org.apache.spark.deploy.worker.Worker, logging to /oasis/projects/nsf/uot143/fegaras/spark-2.2.0-bin-hadoop2.6/logs/spark-fegaras-org.apache.spark.deploy.worker.Worker-1-comet-22-70.sdsc.edu.out
comet-27-53.ibnet: starting org.apache.spark.deploy.worker.Worker, logging to /oasis/projects/nsf/uot143/fegaras/spark-2.2.0-bin-hadoop2.6/logs/spark-fegaras-org.apache.spark.deploy.worker.Worker-1-comet-27-53.sdsc.edu.out
comet-27-45.ibnet: starting org.apache.spark.deploy.worker.Worker, logging to /oasis/projects/nsf/uot143/fegaras/spark-2.2.0-bin-hadoop2.6/logs/spark-fegaras-org.apache.spark.deploy.worker.Worker-1-comet-27-45.sdsc.edu.out
comet-22-57.ibnet: starting org.apache.spark.deploy.worker.Worker, logging to /oasis/projects/nsf/uot143/fegaras/spark-2.2.0-bin-hadoop2.6/logs/spark-fegaras-org.apache.spark.deploy.worker.Worker-1-comet-22-57.sdsc.edu.out
20/02/06 10:33:09 INFO spark.SparkContext: Running Spark version 2.2.0
20/02/06 10:33:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/06 10:33:09 INFO spark.SparkContext: Submitted application: Add
20/02/06 10:33:09 INFO spark.SecurityManager: Changing view acls to: fegaras
20/02/06 10:33:09 INFO spark.SecurityManager: Changing modify acls to: fegaras
20/02/06 10:33:09 INFO spark.SecurityManager: Changing view acls groups to: 
20/02/06 10:33:09 INFO spark.SecurityManager: Changing modify acls groups to: 
20/02/06 10:33:09 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fegaras); groups with view permissions: Set(); users  with modify permissions: Set(fegaras); groups with modify permissions: Set()
20/02/06 10:33:10 INFO util.Utils: Successfully started service 'sparkDriver' on port 41670.
20/02/06 10:33:10 INFO spark.SparkEnv: Registering MapOutputTracker
20/02/06 10:33:10 INFO spark.SparkEnv: Registering BlockManagerMaster
20/02/06 10:33:10 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/06 10:33:10 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/06 10:33:10 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-74ebf227-882d-4e40-8d5f-6d98001cafc6
20/02/06 10:33:10 INFO memory.MemoryStore: MemoryStore started with capacity 12.1 GB
20/02/06 10:33:10 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/02/06 10:33:10 INFO util.log: Logging initialized @1590ms
20/02/06 10:33:10 INFO server.Server: jetty-9.3.z-SNAPSHOT
20/02/06 10:33:10 INFO server.Server: Started @1648ms
20/02/06 10:33:10 INFO server.AbstractConnector: Started ServerConnector@2427e004{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/02/06 10:33:10 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54afd745{/jobs,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3676ac27{/jobs/json,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@48f5bde6{/jobs/job,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7072bc39{/jobs/job/json,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ca65ce4{/stages,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5707c1cb{/stages/json,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35038141{/stages/stage,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50305a{/stages/stage/json,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d511b5f{/stages/pool,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40f33492{/stages/pool/json,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ad3a1bb{/storage,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@324c64cd{/storage/json,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@24be2d9c{/storage/rdd,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@aec50a1{/storage/rdd/json,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70d2e40b{/environment,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a0e1b5e{/environment/json,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@173b9122{/executors,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7646731d{/executors/json,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3b1bb3ab{/executors/threadDump,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40bffbca{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@42a9a63e{/static,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@57f791c6{/,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6c4f9535{/api,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@241a53ef{/jobs/job/kill,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2db2cd5{/stages/stage/kill,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO ui.SparkUI: Bound SparkUI to comet-22-13.ibnet, and started at http://10.22.250.82:4040
20/02/06 10:33:10 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/lib/diql-spark.jar at spark://10.22.250.82:41670/jars/diql-spark.jar with timestamp 1581013990456
20/02/06 10:33:10 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/benchmarks/diablo/test.jar at spark://10.22.250.82:41670/jars/test.jar with timestamp 1581013990456
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://comet-22-13.ibnet:7077...
20/02/06 10:33:10 INFO client.TransportClientFactory: Successfully created connection to comet-22-13.ibnet/10.22.250.82:7077 after 18 ms (0 ms spent in bootstraps)
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20200206103310-0000
20/02/06 10:33:10 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37205.
20/02/06 10:33:10 INFO netty.NettyBlockTransferService: Server created on 10.22.250.82:37205
20/02/06 10:33:10 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/06 10:33:10 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.22.250.82, 37205, None)
20/02/06 10:33:10 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.22.250.82:37205 with 12.1 GB RAM, BlockManagerId(driver, 10.22.250.82, 37205, None)
20/02/06 10:33:10 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.22.250.82, 37205, None)
20/02/06 10:33:10 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.22.250.82, 37205, None)
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/0 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/0 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/1 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/1 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/2 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/2 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/3 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/3 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/4 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/4 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/5 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/5 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/6 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/6 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/7 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/7 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/8 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/8 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/9 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/9 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/10 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/10 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/11 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/11 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/12 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/12 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/13 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/13 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/14 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/14 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/15 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/15 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/16 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/16 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/17 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/17 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/18 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/18 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/19 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/19 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/20 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/20 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/21 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/21 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/22 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/22 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/23 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/23 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/24 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/24 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/25 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/25 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/26 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/26 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/27 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/27 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/28 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/28 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/29 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/29 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/30 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/30 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/31 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/31 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/32 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/32 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/33 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/33 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/34 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/34 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/35 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/35 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/36 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/36 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/37 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/37 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/38 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/38 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/39 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/39 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/0 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/5 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/10 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/15 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/1 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/6 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/11 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/2 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/7 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/16 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/20 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/3 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/12 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/8 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/17 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/4 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/21 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/9 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/13 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/18 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/22 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/30 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/19 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/14 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/25 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/23 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/31 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/26 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/24 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/35 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/32 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/27 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/36 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/33 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/28 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/37 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/34 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/29 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/38 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206103310-0000/39 is now RUNNING
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/40 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/40 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/41 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/41 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/42 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/42 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/43 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/43 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206103310-0000/44 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206103310-0000/44 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:33:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a4c638d{/metrics/json,null,AVAILABLE,@Spark}
20/02/06 10:33:10 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
*** 3576 3576  2.76 GB
12780625
**** AddSpark run time: 53.955 secs
12780625
**** AddDiablo run time: 68.502 secs
12780625
**** AddSpark run time: 39.013 secs
12780625
**** AddDiablo run time: 65.676 secs
12780625
**** AddSpark run time: 56.808 secs
12780625
**** AddDiablo run time: 67.396 secs
12780625
**** AddSpark run time: 47.114 secs
12780625
**** AddDiablo run time: 59.07 secs
20/02/06 10:40:50 INFO spark.SparkContext: Running Spark version 2.2.0
20/02/06 10:40:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/06 10:40:50 INFO spark.SparkContext: Submitted application: Multiply
20/02/06 10:40:50 INFO spark.SecurityManager: Changing view acls to: fegaras
20/02/06 10:40:50 INFO spark.SecurityManager: Changing modify acls to: fegaras
20/02/06 10:40:50 INFO spark.SecurityManager: Changing view acls groups to: 
20/02/06 10:40:50 INFO spark.SecurityManager: Changing modify acls groups to: 
20/02/06 10:40:50 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fegaras); groups with view permissions: Set(); users  with modify permissions: Set(fegaras); groups with modify permissions: Set()
20/02/06 10:40:50 INFO util.Utils: Successfully started service 'sparkDriver' on port 33195.
20/02/06 10:40:50 INFO spark.SparkEnv: Registering MapOutputTracker
20/02/06 10:40:50 INFO spark.SparkEnv: Registering BlockManagerMaster
20/02/06 10:40:50 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/06 10:40:50 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/06 10:40:50 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-08999e92-637c-4162-a783-de9b6f7d80ce
20/02/06 10:40:50 INFO memory.MemoryStore: MemoryStore started with capacity 12.1 GB
20/02/06 10:40:50 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/02/06 10:40:50 INFO util.log: Logging initialized @1485ms
20/02/06 10:40:50 INFO server.Server: jetty-9.3.z-SNAPSHOT
20/02/06 10:40:50 INFO server.Server: Started @1543ms
20/02/06 10:40:50 INFO server.AbstractConnector: Started ServerConnector@2427e004{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/02/06 10:40:50 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54afd745{/jobs,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3676ac27{/jobs/json,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@48f5bde6{/jobs/job,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7072bc39{/jobs/job/json,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ca65ce4{/stages,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5707c1cb{/stages/json,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35038141{/stages/stage,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50305a{/stages/stage/json,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d511b5f{/stages/pool,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40f33492{/stages/pool/json,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ad3a1bb{/storage,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@324c64cd{/storage/json,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@24be2d9c{/storage/rdd,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@aec50a1{/storage/rdd/json,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70d2e40b{/environment,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a0e1b5e{/environment/json,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@173b9122{/executors,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7646731d{/executors/json,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3b1bb3ab{/executors/threadDump,null,AVAILABLE,@Spark}
20/02/06 10:40:50 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40bffbca{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/02/06 10:40:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@42a9a63e{/static,null,AVAILABLE,@Spark}
20/02/06 10:40:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@57f791c6{/,null,AVAILABLE,@Spark}
20/02/06 10:40:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6c4f9535{/api,null,AVAILABLE,@Spark}
20/02/06 10:40:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@241a53ef{/jobs/job/kill,null,AVAILABLE,@Spark}
20/02/06 10:40:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2db2cd5{/stages/stage/kill,null,AVAILABLE,@Spark}
20/02/06 10:40:51 INFO ui.SparkUI: Bound SparkUI to comet-22-13.ibnet, and started at http://10.22.250.82:4040
20/02/06 10:40:51 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/lib/diql-spark.jar at spark://10.22.250.82:33195/jars/diql-spark.jar with timestamp 1581014451021
20/02/06 10:40:51 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/benchmarks/diablo/test.jar at spark://10.22.250.82:33195/jars/test.jar with timestamp 1581014451022
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://comet-22-13.ibnet:7077...
20/02/06 10:40:51 INFO client.TransportClientFactory: Successfully created connection to comet-22-13.ibnet/10.22.250.82:7077 after 18 ms (0 ms spent in bootstraps)
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20200206104051-0001
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/0 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/0 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/1 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/1 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/2 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/2 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/3 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/3 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/4 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/4 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/5 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:40:51 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39882.
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/5 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/6 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:40:51 INFO netty.NettyBlockTransferService: Server created on 10.22.250.82:39882
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/6 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/7 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/7 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/8 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:40:51 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/8 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/9 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/9 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/10 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/10 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/11 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:40:51 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.22.250.82, 39882, None)
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/11 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/12 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/12 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/13 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/13 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/14 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/14 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/15 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/15 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/16 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/16 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/17 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/17 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.22.250.82:39882 with 12.1 GB RAM, BlockManagerId(driver, 10.22.250.82, 39882, None)
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/18 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/18 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/19 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/19 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/20 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/20 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.22.250.82, 39882, None)
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/21 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:40:51 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.22.250.82, 39882, None)
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/21 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/22 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/22 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/23 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/23 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/24 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/24 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/25 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/25 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/26 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/26 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/27 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/27 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/28 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/28 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/29 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/29 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/30 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/30 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/31 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/31 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/32 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/32 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/33 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/33 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/34 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/34 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/35 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/35 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/36 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/36 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/37 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/37 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/38 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/38 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/39 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/39 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/40 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/40 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/41 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/41 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/42 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/42 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/43 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/43 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/44 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/44 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/45 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/45 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/46 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/46 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/47 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/47 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/48 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/48 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104051-0001/49 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104051-0001/49 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/0 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/1 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/2 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/3 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/10 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/11 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/12 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/5 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/13 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/6 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/7 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/4 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/20 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/14 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/21 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/22 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/8 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/25 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/15 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/23 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/26 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/16 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/27 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/17 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/18 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/30 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/31 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/32 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/28 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/35 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/36 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/9 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/37 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/38 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/24 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/33 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/40 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/41 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/42 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/43 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/45 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/39 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/46 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/47 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/48 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/49 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/44 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/19 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/29 is now RUNNING
20/02/06 10:40:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104051-0001/34 is now RUNNING
20/02/06 10:40:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a4c638d{/metrics/json,null,AVAILABLE,@Spark}
20/02/06 10:40:51 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
*** 1788 1788  0.69 GB
3193369
**** MultiplySpark run time: 59.35 secs
3193369
**** MultiplyDiablo run time: 53.615 secs
3193369
**** MultiplySpark run time: 52.081 secs
3193369
**** MultiplyDiablo run time: 54.554 secs
3193369
**** MultiplySpark run time: 51.84 secs
3193369
**** MultiplyDiablo run time: 54.07 secs
3193369
**** MultiplySpark run time: 51.76 secs
3193369
**** MultiplyDiablo run time: 53.87 secs
20/02/06 10:48:04 INFO spark.SparkContext: Running Spark version 2.2.0
20/02/06 10:48:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/06 10:48:04 INFO spark.SparkContext: Submitted application: Add
20/02/06 10:48:04 INFO spark.SecurityManager: Changing view acls to: fegaras
20/02/06 10:48:04 INFO spark.SecurityManager: Changing modify acls to: fegaras
20/02/06 10:48:04 INFO spark.SecurityManager: Changing view acls groups to: 
20/02/06 10:48:04 INFO spark.SecurityManager: Changing modify acls groups to: 
20/02/06 10:48:04 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fegaras); groups with view permissions: Set(); users  with modify permissions: Set(fegaras); groups with modify permissions: Set()
20/02/06 10:48:04 INFO util.Utils: Successfully started service 'sparkDriver' on port 43378.
20/02/06 10:48:04 INFO spark.SparkEnv: Registering MapOutputTracker
20/02/06 10:48:04 INFO spark.SparkEnv: Registering BlockManagerMaster
20/02/06 10:48:04 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/06 10:48:04 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/06 10:48:04 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-ffacf5b3-1ff4-4630-9e78-0eefeed82360
20/02/06 10:48:04 INFO memory.MemoryStore: MemoryStore started with capacity 12.1 GB
20/02/06 10:48:05 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/02/06 10:48:05 INFO util.log: Logging initialized @1476ms
20/02/06 10:48:05 INFO server.Server: jetty-9.3.z-SNAPSHOT
20/02/06 10:48:05 INFO server.Server: Started @1538ms
20/02/06 10:48:05 INFO server.AbstractConnector: Started ServerConnector@2427e004{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/02/06 10:48:05 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54afd745{/jobs,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3676ac27{/jobs/json,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@48f5bde6{/jobs/job,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7072bc39{/jobs/job/json,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ca65ce4{/stages,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5707c1cb{/stages/json,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35038141{/stages/stage,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50305a{/stages/stage/json,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d511b5f{/stages/pool,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40f33492{/stages/pool/json,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ad3a1bb{/storage,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@324c64cd{/storage/json,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@24be2d9c{/storage/rdd,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@aec50a1{/storage/rdd/json,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70d2e40b{/environment,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a0e1b5e{/environment/json,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@173b9122{/executors,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7646731d{/executors/json,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3b1bb3ab{/executors/threadDump,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40bffbca{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@42a9a63e{/static,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@57f791c6{/,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6c4f9535{/api,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@241a53ef{/jobs/job/kill,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2db2cd5{/stages/stage/kill,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO ui.SparkUI: Bound SparkUI to comet-22-13.ibnet, and started at http://10.22.250.82:4040
20/02/06 10:48:05 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/lib/diql-spark.jar at spark://10.22.250.82:43378/jars/diql-spark.jar with timestamp 1581014885195
20/02/06 10:48:05 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/benchmarks/diablo/test.jar at spark://10.22.250.82:43378/jars/test.jar with timestamp 1581014885196
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://comet-22-13.ibnet:7077...
20/02/06 10:48:05 INFO client.TransportClientFactory: Successfully created connection to comet-22-13.ibnet/10.22.250.82:7077 after 18 ms (0 ms spent in bootstraps)
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20200206104805-0002
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/0 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/0 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/1 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/1 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/2 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/2 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/3 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/3 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/4 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 10:48:05 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40625.
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/4 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/5 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:48:05 INFO netty.NettyBlockTransferService: Server created on 10.22.250.82:40625
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/5 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/6 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/6 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/7 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:48:05 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.22.250.82, 40625, None)
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/7 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/8 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/8 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/9 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 10:48:05 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.22.250.82:40625 with 12.1 GB RAM, BlockManagerId(driver, 10.22.250.82, 40625, None)
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/9 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/10 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/10 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/11 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/11 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/12 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/12 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/13 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:48:05 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.22.250.82, 40625, None)
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/13 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/14 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 10:48:05 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.22.250.82, 40625, None)
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/14 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/15 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/15 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/16 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/16 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/17 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/17 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/18 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/18 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/19 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/19 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/20 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/20 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/21 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/21 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/22 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/22 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/23 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/23 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/24 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/24 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/25 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/25 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/26 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/26 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/27 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/27 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/28 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/28 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/29 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/29 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/30 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/30 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/31 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/31 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/32 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/32 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/33 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/33 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/34 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/34 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/35 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/35 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/36 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/36 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/37 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/37 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/38 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/38 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/39 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/39 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/40 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/40 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/41 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/41 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/42 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/42 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/43 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/43 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/44 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/44 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/45 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/45 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/46 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/46 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/47 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/47 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/48 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/48 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206104805-0002/49 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206104805-0002/49 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/5 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/15 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/6 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/16 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/20 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/21 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/25 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/0 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/10 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/22 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/7 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/17 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/35 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/11 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/36 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/1 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/26 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/40 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/27 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/37 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/12 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/41 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/30 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/31 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/42 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/18 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/45 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/32 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/46 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/33 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/28 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/2 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/47 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/13 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/38 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/23 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/43 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/34 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/29 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/48 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/3 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/44 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/19 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/49 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/39 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/14 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/4 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/8 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/9 is now RUNNING
20/02/06 10:48:05 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206104805-0002/24 is now RUNNING
20/02/06 10:48:05 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a4c638d{/metrics/json,null,AVAILABLE,@Spark}
20/02/06 10:48:05 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
*** 5056 5056  5.52 GB
25553025
**** AddSpark run time: 133.789 secs
25553025
**** AddDiablo run time: 156.335 secs
25553025
**** AddSpark run time: 127.535 secs
25553025
**** AddDiablo run time: 146.06 secs
25553025
**** AddSpark run time: 107.712 secs
25553025
**** AddDiablo run time: 162.933 secs
25553025
**** AddSpark run time: 119.085 secs
20/02/06 11:05:02 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 23.0 (TID 46, 198.202.113.133, executor 33): java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:479)
	at java.io.ObjectInputStream$PeekInputStream.read(ObjectInputStream.java:2662)
	at java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2678)
	at java.io.ObjectInputStream$BlockDataInputStream.readInt(ObjectInputStream.java:3179)
	at java.io.ObjectInputStream.readHandle(ObjectInputStream.java:1683)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1744)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2041)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1572)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:430)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:158)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:188)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:154)
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

25553025
**** AddDiablo run time: 170.233 secs
20/02/06 11:06:50 INFO spark.SparkContext: Running Spark version 2.2.0
20/02/06 11:06:50 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/06 11:06:51 INFO spark.SparkContext: Submitted application: Multiply
20/02/06 11:06:51 INFO spark.SecurityManager: Changing view acls to: fegaras
20/02/06 11:06:51 INFO spark.SecurityManager: Changing modify acls to: fegaras
20/02/06 11:06:51 INFO spark.SecurityManager: Changing view acls groups to: 
20/02/06 11:06:51 INFO spark.SecurityManager: Changing modify acls groups to: 
20/02/06 11:06:51 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fegaras); groups with view permissions: Set(); users  with modify permissions: Set(fegaras); groups with modify permissions: Set()
20/02/06 11:06:51 INFO util.Utils: Successfully started service 'sparkDriver' on port 35082.
20/02/06 11:06:51 INFO spark.SparkEnv: Registering MapOutputTracker
20/02/06 11:06:51 INFO spark.SparkEnv: Registering BlockManagerMaster
20/02/06 11:06:51 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/06 11:06:51 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/06 11:06:51 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-f423e6a9-996f-4982-8ef2-42650fdf9de2
20/02/06 11:06:51 INFO memory.MemoryStore: MemoryStore started with capacity 12.1 GB
20/02/06 11:06:51 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/02/06 11:06:51 INFO util.log: Logging initialized @1483ms
20/02/06 11:06:51 INFO server.Server: jetty-9.3.z-SNAPSHOT
20/02/06 11:06:51 INFO server.Server: Started @1541ms
20/02/06 11:06:51 INFO server.AbstractConnector: Started ServerConnector@2427e004{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/02/06 11:06:51 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54afd745{/jobs,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3676ac27{/jobs/json,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@48f5bde6{/jobs/job,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7072bc39{/jobs/job/json,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ca65ce4{/stages,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5707c1cb{/stages/json,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35038141{/stages/stage,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50305a{/stages/stage/json,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d511b5f{/stages/pool,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40f33492{/stages/pool/json,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ad3a1bb{/storage,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@324c64cd{/storage/json,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@24be2d9c{/storage/rdd,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@aec50a1{/storage/rdd/json,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70d2e40b{/environment,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a0e1b5e{/environment/json,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@173b9122{/executors,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7646731d{/executors/json,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3b1bb3ab{/executors/threadDump,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40bffbca{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@42a9a63e{/static,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@57f791c6{/,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6c4f9535{/api,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@241a53ef{/jobs/job/kill,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2db2cd5{/stages/stage/kill,null,AVAILABLE,@Spark}
20/02/06 11:06:51 INFO ui.SparkUI: Bound SparkUI to comet-22-13.ibnet, and started at http://10.22.250.82:4040
20/02/06 11:06:51 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/lib/diql-spark.jar at spark://10.22.250.82:35082/jars/diql-spark.jar with timestamp 1581016011695
20/02/06 11:06:51 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/benchmarks/diablo/test.jar at spark://10.22.250.82:35082/jars/test.jar with timestamp 1581016011695
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://comet-22-13.ibnet:7077...
20/02/06 11:06:51 INFO client.TransportClientFactory: Successfully created connection to comet-22-13.ibnet/10.22.250.82:7077 after 18 ms (0 ms spent in bootstraps)
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20200206110651-0003
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/0 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/0 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/1 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/1 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/2 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/2 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/3 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 11:06:51 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34197.
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/3 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO netty.NettyBlockTransferService: Server created on 10.22.250.82:34197
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/4 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/4 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/5 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 11:06:51 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/5 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/6 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/6 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/7 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 11:06:51 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.22.250.82, 34197, None)
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/7 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/8 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/8 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/9 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 11:06:51 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.22.250.82:34197 with 12.1 GB RAM, BlockManagerId(driver, 10.22.250.82, 34197, None)
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/9 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/10 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/10 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/11 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/11 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/12 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/12 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/13 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/13 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.22.250.82, 34197, None)
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/14 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 11:06:51 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.22.250.82, 34197, None)
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/14 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/15 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/15 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/16 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/16 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/17 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/17 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/18 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/18 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/19 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/19 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/20 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/20 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/21 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/21 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/22 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/22 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/23 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/23 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/24 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/24 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/25 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/25 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/26 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/26 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/27 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/27 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/28 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/28 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/29 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/29 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/30 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/30 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/31 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/31 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/32 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/32 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/33 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/33 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/34 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/34 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/35 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/35 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/36 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/36 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/37 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/37 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/38 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/38 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/39 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/39 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/40 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/40 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/41 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/41 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/42 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/42 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/43 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/43 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/44 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/44 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/45 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/45 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/46 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/46 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/47 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/47 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/48 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/48 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206110651-0003/49 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 11:06:51 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206110651-0003/49 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/0 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/10 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/20 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/30 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/1 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/15 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/25 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/16 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/11 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/21 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/26 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/31 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/35 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/2 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/22 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/17 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/12 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/40 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/32 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/36 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/41 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/27 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/45 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/3 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/5 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/13 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/23 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/46 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/37 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/42 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/28 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/6 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/47 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/33 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/38 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/43 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/24 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/14 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/4 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/48 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/44 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/39 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/49 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/7 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/34 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/29 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/8 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/9 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/18 is now RUNNING
20/02/06 11:06:51 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206110651-0003/19 is now RUNNING
20/02/06 11:06:51 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a4c638d{/metrics/json,null,AVAILABLE,@Spark}
20/02/06 11:06:52 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
*** 2528 2528  1.38 GB
6385729
**** MultiplySpark run time: 144.161 secs
20/02/06 11:10:03 WARN scheduler.TaskSetManager: Lost task 19.0 in stage 5.0 (TID 127, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=2, mapId=0, reduceId=19, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 11:10:03 WARN scheduler.TaskSetManager: Lost task 8.0 in stage 5.0 (TID 116, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=2, mapId=0, reduceId=8, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 11:10:03 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_3_1 !
20/02/06 11:10:03 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1_0 !
20/02/06 11:10:03 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1_1 !
20/02/06 11:10:03 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_3_0 !
20/02/06 11:10:03 WARN scheduler.TaskSetManager: Lost task 9.0 in stage 5.0 (TID 117, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=2, mapId=0, reduceId=9, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 11:10:03 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 5.0 (TID 124, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=2, mapId=0, reduceId=16, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
6385729
**** MultiplyDiablo run time: 200.376 secs
20/02/06 11:13:22 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 8.0 (TID 239, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=4, mapId=1, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9796 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 36 more

)
20/02/06 11:13:22 WARN scheduler.TaskSetManager: Lost task 40.0 in stage 8.0 (TID 277, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=4, mapId=1, reduceId=40, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
20/02/06 11:13:23 WARN scheduler.TaskSetManager: Lost task 34.0 in stage 8.0 (TID 271, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=4, mapId=1, reduceId=34, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9825 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 36 more

)
20/02/06 11:13:23 WARN scheduler.TaskSetManager: Lost task 24.0 in stage 8.0 (TID 261, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=4, mapId=1, reduceId=24, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
20/02/06 11:13:23 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 8.0 (TID 242, 198.202.113.122, executor 6): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=4, mapId=1, reduceId=5, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
20/02/06 11:13:23 WARN scheduler.TaskSetManager: Lost task 25.0 in stage 8.0 (TID 262, 198.202.113.122, executor 6): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=4, mapId=1, reduceId=25, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:208)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
20/02/06 11:13:23 WARN scheduler.TaskSetManager: Lost task 38.0 in stage 8.0 (TID 275, 198.202.113.122, executor 8): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=4, mapId=1, reduceId=38, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
20/02/06 11:13:23 WARN scheduler.TaskSetManager: Lost task 28.0 in stage 8.0 (TID 265, 198.202.113.122, executor 8): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=4, mapId=1, reduceId=28, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9912 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 36 more

)
20/02/06 11:13:23 WARN scheduler.TaskSetManager: Lost task 29.0 in stage 8.0 (TID 266, 198.202.113.122, executor 5): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=4, mapId=1, reduceId=29, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
6385729
**** MultiplySpark run time: 179.109 secs
6385729
**** MultiplyDiablo run time: 149.194 secs
20/02/06 11:18:49 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 14.0 (TID 490, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=8, mapId=0, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
20/02/06 11:18:49 WARN scheduler.TaskSetManager: Lost task 9.0 in stage 14.0 (TID 496, 198.202.115.208, executor 4): FetchFailed(null, shuffleId=8, mapId=-1, reduceId=9, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 8
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 11:18:49 WARN scheduler.TaskSetManager: Lost task 39.0 in stage 14.0 (TID 526, 198.202.115.208, executor 4): FetchFailed(null, shuffleId=8, mapId=-1, reduceId=39, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 8
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 11:18:49 WARN scheduler.TaskSetManager: Lost task 29.0 in stage 14.0 (TID 516, 198.202.115.208, executor 4): FetchFailed(null, shuffleId=8, mapId=-1, reduceId=29, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 8
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 11:18:49 WARN scheduler.TaskSetManager: Lost task 19.0 in stage 14.0 (TID 506, 198.202.115.208, executor 4): FetchFailed(null, shuffleId=8, mapId=-1, reduceId=19, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 8
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 11:18:50 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 14.0 (TID 487, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=8, mapId=0, reduceId=0, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
6385729
**** MultiplySpark run time: 180.107 secs
20/02/06 11:21:54 WARN scheduler.TaskSetManager: Lost task 22.0 in stage 17.0 (TID 655, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 43019, None), shuffleId=10, mapId=0, reduceId=22, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9708 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 39 more

)
6385729
**** MultiplyDiablo run time: 188.898 secs
6385729
**** MultiplySpark run time: 128.202 secs
6385729
**** MultiplyDiablo run time: 147.486 secs
20/02/06 11:28:52 INFO spark.SparkContext: Running Spark version 2.2.0
20/02/06 11:28:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/06 11:28:52 INFO spark.SparkContext: Submitted application: Add
20/02/06 11:28:52 INFO spark.SecurityManager: Changing view acls to: fegaras
20/02/06 11:28:52 INFO spark.SecurityManager: Changing modify acls to: fegaras
20/02/06 11:28:52 INFO spark.SecurityManager: Changing view acls groups to: 
20/02/06 11:28:52 INFO spark.SecurityManager: Changing modify acls groups to: 
20/02/06 11:28:52 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fegaras); groups with view permissions: Set(); users  with modify permissions: Set(fegaras); groups with modify permissions: Set()
20/02/06 11:28:52 INFO util.Utils: Successfully started service 'sparkDriver' on port 40516.
20/02/06 11:28:52 INFO spark.SparkEnv: Registering MapOutputTracker
20/02/06 11:28:52 INFO spark.SparkEnv: Registering BlockManagerMaster
20/02/06 11:28:52 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/06 11:28:52 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/06 11:28:52 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-8ce37c78-6f8d-4892-922a-f5a1f1572344
20/02/06 11:28:52 INFO memory.MemoryStore: MemoryStore started with capacity 12.1 GB
20/02/06 11:28:52 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/02/06 11:28:52 INFO util.log: Logging initialized @1507ms
20/02/06 11:28:53 INFO server.Server: jetty-9.3.z-SNAPSHOT
20/02/06 11:28:53 INFO server.Server: Started @1570ms
20/02/06 11:28:53 INFO server.AbstractConnector: Started ServerConnector@3ec21041{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/02/06 11:28:53 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10027fc9{/jobs,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5489c777{/jobs/json,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62f87c44{/jobs/job,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5149f008{/jobs/job/json,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@158d255c{/stages,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@327120c8{/stages/json,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2b5cb9b2{/stages/stage,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2970a5bc{/stages/stage/json,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@72efb5c1{/stages/pool,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@41200e0c{/stages/pool/json,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4fbdc0f0{/storage,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bc28a83{/storage/json,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@13579834{/storage/rdd,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5bd73d1a{/storage/rdd/json,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2555fff0{/environment,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@120f38e6{/environment/json,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@702ed190{/executors,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7c18432b{/executors/json,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70e29e14{/executors/threadDump,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a4bef8{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2449cff7{/static,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1a15b789{/,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51650883{/api,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@c1fca1e{/jobs/job/kill,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@344344fa{/stages/stage/kill,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO ui.SparkUI: Bound SparkUI to comet-22-13.ibnet, and started at http://10.22.250.82:4040
20/02/06 11:28:53 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/lib/diql-spark.jar at spark://10.22.250.82:40516/jars/diql-spark.jar with timestamp 1581017333125
20/02/06 11:28:53 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/benchmarks/diablo/test.jar at spark://10.22.250.82:40516/jars/test.jar with timestamp 1581017333125
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://comet-22-13.ibnet:7077...
20/02/06 11:28:53 INFO client.TransportClientFactory: Successfully created connection to comet-22-13.ibnet/10.22.250.82:7077 after 18 ms (0 ms spent in bootstraps)
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20200206112853-0004
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/0 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/0 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/1 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/1 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/2 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/2 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/3 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/3 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/4 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/4 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43010.
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/5 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/5 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/6 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/6 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/7 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/7 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/8 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 11:28:53 INFO netty.NettyBlockTransferService: Server created on 10.22.250.82:43010
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/8 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/9 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/9 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/10 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 11:28:53 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/10 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/11 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/11 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/12 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/12 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/13 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/13 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.22.250.82, 43010, None)
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/14 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/14 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/15 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/15 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/16 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/16 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/17 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/17 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/18 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/18 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.22.250.82:43010 with 12.1 GB RAM, BlockManagerId(driver, 10.22.250.82, 43010, None)
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/19 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/19 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/20 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/20 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/21 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/21 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/22 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/22 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/23 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 11:28:53 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.22.250.82, 43010, None)
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/23 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/24 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 11:28:53 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.22.250.82, 43010, None)
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/24 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/25 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/25 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/26 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/26 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/27 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/27 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/28 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/28 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/29 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/29 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/30 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/30 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/31 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/31 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/32 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/32 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/33 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/33 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/34 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/34 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/35 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/35 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/36 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/36 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/37 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/37 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/38 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/38 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/39 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/39 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/40 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/40 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/41 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/41 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/42 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/42 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/43 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/43 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/44 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/44 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/45 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/45 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/46 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/46 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/47 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/47 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/48 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/48 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206112853-0004/49 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206112853-0004/49 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/5 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/10 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/0 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/20 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/15 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/25 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/30 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/21 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/6 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/26 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/16 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/31 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/11 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/35 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/1 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/12 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/27 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/7 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/22 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/40 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/45 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/17 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/32 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/41 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/36 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/46 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/28 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/13 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/33 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/47 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/23 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/37 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/18 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/42 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/48 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/8 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/43 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/29 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/38 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/49 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/14 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/19 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/9 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/34 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/44 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/2 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/24 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/39 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/3 is now RUNNING
20/02/06 11:28:53 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206112853-0004/4 is now RUNNING
20/02/06 11:28:53 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@781a9412{/metrics/json,null,AVAILABLE,@Spark}
20/02/06 11:28:53 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
*** 6192 6192  8.28 GB
38328481
**** AddSpark run time: 291.06 secs
38328481
**** AddDiablo run time: 305.146 secs
38328481
**** AddSpark run time: 254.888 secs
38328481
**** AddDiablo run time: 303.531 secs
38328481
**** AddSpark run time: 226.571 secs
38328481
**** AddDiablo run time: 307.579 secs
38328481
**** AddSpark run time: 219.44 secs
38328481
**** AddDiablo run time: 276.378 secs
20/02/06 12:05:20 INFO spark.SparkContext: Running Spark version 2.2.0
20/02/06 12:05:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/06 12:05:20 INFO spark.SparkContext: Submitted application: Multiply
20/02/06 12:05:20 INFO spark.SecurityManager: Changing view acls to: fegaras
20/02/06 12:05:20 INFO spark.SecurityManager: Changing modify acls to: fegaras
20/02/06 12:05:20 INFO spark.SecurityManager: Changing view acls groups to: 
20/02/06 12:05:20 INFO spark.SecurityManager: Changing modify acls groups to: 
20/02/06 12:05:20 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fegaras); groups with view permissions: Set(); users  with modify permissions: Set(fegaras); groups with modify permissions: Set()
20/02/06 12:05:20 INFO util.Utils: Successfully started service 'sparkDriver' on port 46761.
20/02/06 12:05:20 INFO spark.SparkEnv: Registering MapOutputTracker
20/02/06 12:05:20 INFO spark.SparkEnv: Registering BlockManagerMaster
20/02/06 12:05:20 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/06 12:05:20 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/06 12:05:20 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-d0bb9ff0-5a28-4a57-8314-34ef383fc9ed
20/02/06 12:05:20 INFO memory.MemoryStore: MemoryStore started with capacity 12.1 GB
20/02/06 12:05:20 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/02/06 12:05:20 INFO util.log: Logging initialized @1473ms
20/02/06 12:05:21 INFO server.Server: jetty-9.3.z-SNAPSHOT
20/02/06 12:05:21 INFO server.Server: Started @1531ms
20/02/06 12:05:21 INFO server.AbstractConnector: Started ServerConnector@5ce3fcda{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/02/06 12:05:21 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54afd745{/jobs,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3676ac27{/jobs/json,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@48f5bde6{/jobs/job,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7072bc39{/jobs/job/json,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ca65ce4{/stages,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5707c1cb{/stages/json,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35038141{/stages/stage,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50305a{/stages/stage/json,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d511b5f{/stages/pool,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40f33492{/stages/pool/json,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ad3a1bb{/storage,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@324c64cd{/storage/json,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@24be2d9c{/storage/rdd,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@aec50a1{/storage/rdd/json,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70d2e40b{/environment,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a0e1b5e{/environment/json,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@173b9122{/executors,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7646731d{/executors/json,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3b1bb3ab{/executors/threadDump,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40bffbca{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@42a9a63e{/static,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@57f791c6{/,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6c4f9535{/api,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@241a53ef{/jobs/job/kill,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2db2cd5{/stages/stage/kill,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO ui.SparkUI: Bound SparkUI to comet-22-13.ibnet, and started at http://10.22.250.82:4040
20/02/06 12:05:21 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/lib/diql-spark.jar at spark://10.22.250.82:46761/jars/diql-spark.jar with timestamp 1581019521097
20/02/06 12:05:21 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/benchmarks/diablo/test.jar at spark://10.22.250.82:46761/jars/test.jar with timestamp 1581019521097
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://comet-22-13.ibnet:7077...
20/02/06 12:05:21 INFO client.TransportClientFactory: Successfully created connection to comet-22-13.ibnet/10.22.250.82:7077 after 18 ms (0 ms spent in bootstraps)
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20200206120521-0005
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/0 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/0 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/1 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/1 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/2 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/2 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/3 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/3 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/4 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 12:05:21 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39130.
20/02/06 12:05:21 INFO netty.NettyBlockTransferService: Server created on 10.22.250.82:39130
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/4 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/5 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/5 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/6 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/6 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/7 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 12:05:21 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.22.250.82, 39130, None)
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/7 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/8 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/8 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/9 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/9 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/10 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/10 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.22.250.82:39130 with 12.1 GB RAM, BlockManagerId(driver, 10.22.250.82, 39130, None)
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/11 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/11 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/12 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/12 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/13 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/13 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/14 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/14 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.22.250.82, 39130, None)
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/15 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/15 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.22.250.82, 39130, None)
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/16 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/16 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/17 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/17 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/18 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/18 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/19 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/19 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/20 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/20 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/21 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/21 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/22 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/22 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/23 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/23 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/24 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/24 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/25 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/25 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/26 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/26 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/27 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/27 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/28 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/28 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/29 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/29 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/30 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/30 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/31 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/31 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/32 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/32 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/33 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/33 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/34 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/34 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/35 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/35 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/36 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/36 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/37 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/37 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/38 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/38 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/39 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/39 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/40 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/40 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/41 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/41 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/42 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/42 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/43 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/43 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/44 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/44 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/45 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/45 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/46 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/46 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/47 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/47 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/48 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/48 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206120521-0005/49 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206120521-0005/49 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/5 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/20 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/25 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/30 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/35 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/6 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/40 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/21 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/45 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/26 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/31 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/36 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/41 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/7 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/46 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/27 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/32 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/22 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/15 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/37 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/28 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/8 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/47 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/42 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/33 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/23 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/0 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/38 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/48 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/16 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/10 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/9 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/1 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/24 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/29 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/49 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/39 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/34 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/11 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/43 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/2 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/17 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/12 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/18 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/44 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/3 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/13 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/19 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/4 is now RUNNING
20/02/06 12:05:21 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206120521-0005/14 is now RUNNING
20/02/06 12:05:21 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a4c638d{/metrics/json,null,AVAILABLE,@Spark}
20/02/06 12:05:21 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
*** 3096 3096  2.07 GB
20/02/06 12:06:43 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 2.0 (TID 6, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=0, mapId=1, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
20/02/06 12:06:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_3_1 !
20/02/06 12:06:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1_0 !
20/02/06 12:06:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1_1 !
20/02/06 12:06:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_3_0 !
9579025
**** MultiplySpark run time: 333.573 secs
9579025
**** MultiplyDiablo run time: 248.297 secs
9579025
**** MultiplySpark run time: 250.466 secs
9579025
**** MultiplyDiablo run time: 244.984 secs
20/02/06 12:24:33 WARN scheduler.TaskSetManager: Lost task 57.0 in stage 14.0 (TID 502, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=57, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:24:33 WARN scheduler.TaskSetManager: Lost task 97.0 in stage 14.0 (TID 542, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=97, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7295 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:21 WARN scheduler.TaskSetManager: Lost task 72.0 in stage 14.0 (TID 517, 198.202.119.194, executor 26): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=72, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7225 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:21 WARN scheduler.TaskSetManager: Lost task 74.0 in stage 14.0 (TID 519, 198.202.119.194, executor 28): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=74, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:27 WARN scheduler.TaskSetManager: Lost task 56.0 in stage 14.0 (TID 501, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=56, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:27 WARN scheduler.TaskSetManager: Lost task 96.0 in stage 14.0 (TID 541, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=96, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:28 WARN scheduler.TaskSetManager: Lost task 64.0 in stage 14.0 (TID 509, 198.202.119.194, executor 25): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=64, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7308 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:28 WARN scheduler.TaskSetManager: Lost task 69.0 in stage 14.0 (TID 514, 198.202.119.194, executor 27): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=69, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:29 WARN scheduler.TaskSetManager: Lost task 60.0 in stage 14.0 (TID 505, 198.202.119.194, executor 29): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=60, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:30 WARN scheduler.TaskSetManager: Lost task 71.0 in stage 14.0 (TID 516, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=71, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:30 WARN scheduler.TaskSetManager: Lost task 85.0 in stage 14.0 (TID 530, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=85, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7155 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:30 WARN scheduler.TaskSetManager: Lost task 45.0 in stage 14.0 (TID 490, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=45, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:33 WARN scheduler.TaskSetManager: Lost task 8.0 in stage 14.0 (TID 453, 198.202.119.204, executor 36): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=8, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7261 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:33 WARN scheduler.TaskSetManager: Lost task 38.0 in stage 14.0 (TID 483, 198.202.119.204, executor 36): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=38, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:33 WARN scheduler.TaskSetManager: Lost task 28.0 in stage 14.0 (TID 473, 198.202.119.204, executor 36): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=28, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7407 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:34 WARN scheduler.TaskSetManager: Lost task 18.0 in stage 14.0 (TID 463, 198.202.119.204, executor 36): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=18, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:35 WARN scheduler.TaskSetManager: Lost task 30.0 in stage 14.0 (TID 475, 198.202.119.204, executor 39): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=30, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7149 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:35 WARN scheduler.TaskSetManager: Lost task 20.0 in stage 14.0 (TID 465, 198.202.119.204, executor 39): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=20, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:35 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 14.0 (TID 445, 198.202.119.204, executor 39): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=0, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:35 WARN scheduler.TaskSetManager: Lost task 10.0 in stage 14.0 (TID 455, 198.202.119.204, executor 39): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=10, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:35 WARN scheduler.TaskSetManager: Lost task 84.0 in stage 14.0 (TID 529, 198.202.115.205, executor 22): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=84, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:36 WARN scheduler.TaskSetManager: Lost task 82.0 in stage 14.0 (TID 527, 198.202.115.205, executor 21): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=82, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:36 WARN scheduler.TaskSetManager: Lost task 61.0 in stage 14.0 (TID 506, 198.202.113.133, executor 31): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=61, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7227 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:37 WARN scheduler.TaskSetManager: Lost task 42.0 in stage 14.0 (TID 487, 198.202.115.205, executor 21): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=42, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:37 WARN scheduler.TaskSetManager: Lost task 44.0 in stage 14.0 (TID 489, 198.202.115.205, executor 22): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=44, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7123 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:38 WARN scheduler.TaskSetManager: Lost task 75.0 in stage 14.0 (TID 520, 198.202.113.122, executor 9): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=75, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7179 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:38 WARN scheduler.TaskSetManager: Lost task 89.0 in stage 14.0 (TID 534, 198.202.115.136, executor 16): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=89, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:38 WARN scheduler.TaskSetManager: Lost task 26.0 in stage 14.0 (TID 471, 198.202.115.208, executor 3): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=26, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7342 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:38 WARN scheduler.TaskSetManager: Lost task 77.0 in stage 14.0 (TID 522, 198.202.115.136, executor 17): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=77, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7954 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:39 WARN scheduler.TaskSetManager: Lost task 6.0 in stage 14.0 (TID 451, 198.202.115.208, executor 3): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=6, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:39 WARN scheduler.TaskSetManager: Lost task 36.0 in stage 14.0 (TID 481, 198.202.115.208, executor 3): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=36, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:39 WARN scheduler.TaskSetManager: Lost task 23.0 in stage 14.0 (TID 468, 198.202.115.208, executor 4): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=23, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7199 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:40 WARN scheduler.TaskSetManager: Lost task 33.0 in stage 14.0 (TID 478, 198.202.115.208, executor 4): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=33, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:40 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 14.0 (TID 448, 198.202.115.208, executor 4): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7242 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:40 WARN scheduler.TaskSetManager: Lost task 17.0 in stage 14.0 (TID 462, 198.202.119.204, executor 38): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=17, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:40 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 14.0 (TID 461, 198.202.115.208, executor 3): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=16, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7207 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:40 WARN scheduler.TaskSetManager: Lost task 37.0 in stage 14.0 (TID 482, 198.202.119.204, executor 38): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=37, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:40 WARN scheduler.TaskSetManager: Lost task 13.0 in stage 14.0 (TID 458, 198.202.115.208, executor 4): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=13, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:40 WARN scheduler.TaskSetManager: Lost task 27.0 in stage 14.0 (TID 472, 198.202.119.204, executor 38): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=27, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:41 WARN scheduler.TaskSetManager: Lost task 52.0 in stage 14.0 (TID 497, 198.202.113.202, executor 45): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=52, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:41 WARN scheduler.TaskSetManager: Lost task 7.0 in stage 14.0 (TID 452, 198.202.119.204, executor 38): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=7, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:41 WARN scheduler.TaskSetManager: Lost task 49.0 in stage 14.0 (TID 494, 198.202.115.136, executor 16): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=49, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:41 WARN scheduler.TaskSetManager: Lost task 79.0 in stage 14.0 (TID 524, 198.202.115.205, executor 24): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=79, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7151 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:42 WARN scheduler.TaskSetManager: Lost task 78.0 in stage 14.0 (TID 523, 198.202.115.136, executor 19): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=78, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:42 WARN scheduler.TaskSetManager: Lost task 31.0 in stage 14.0 (TID 476, 198.202.115.208, executor 0): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=31, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7226 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:42 WARN scheduler.TaskSetManager: Lost task 70.0 in stage 14.0 (TID 515, 198.202.113.122, executor 5): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=70, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:42 WARN scheduler.TaskSetManager: Lost task 92.0 in stage 14.0 (TID 537, 198.202.113.202, executor 45): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=92, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:42 WARN scheduler.TaskSetManager: Lost task 25.0 in stage 14.0 (TID 470, 198.202.115.208, executor 2): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=25, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:43 WARN scheduler.TaskSetManager: Lost task 93.0 in stage 14.0 (TID 538, 198.202.115.205, executor 23): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=93, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:43 WARN scheduler.TaskSetManager: Lost task 67.0 in stage 14.0 (TID 512, 198.202.115.136, executor 18): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=67, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:43 WARN scheduler.TaskSetManager: Lost task 66.0 in stage 14.0 (TID 511, 198.202.113.204, executor 41): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=66, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:43 WARN scheduler.TaskSetManager: Lost task 91.0 in stage 14.0 (TID 536, 198.202.115.133, executor 12): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=91, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:43 WARN scheduler.TaskSetManager: Lost task 51.0 in stage 14.0 (TID 496, 198.202.115.133, executor 12): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=51, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:43 WARN scheduler.TaskSetManager: Lost task 58.0 in stage 14.0 (TID 503, 198.202.113.204, executor 43): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=58, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:43 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 14.0 (TID 450, 198.202.115.208, executor 2): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=5, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:43 WARN scheduler.TaskSetManager: Lost task 35.0 in stage 14.0 (TID 480, 198.202.115.208, executor 2): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=35, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:43 WARN scheduler.TaskSetManager: Lost task 53.0 in stage 14.0 (TID 498, 198.202.115.205, executor 23): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=53, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7340 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:44 WARN scheduler.TaskSetManager: Lost task 15.0 in stage 14.0 (TID 460, 198.202.115.208, executor 2): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=15, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:44 WARN scheduler.TaskSetManager: Lost task 80.0 in stage 14.0 (TID 525, 198.202.113.122, executor 7): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=80, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7366 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:45 WARN scheduler.TaskSetManager: Lost task 19.0 in stage 14.0 (TID 464, 198.202.119.204, executor 35): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=19, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:45 WARN scheduler.TaskSetManager: Lost task 98.0 in stage 14.0 (TID 543, 198.202.113.204, executor 43): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=98, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:45 WARN scheduler.TaskSetManager: Lost task 68.0 in stage 14.0 (TID 513, 198.202.115.205, executor 20): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=68, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:45 WARN scheduler.TaskSetManager: Lost task 40.0 in stage 14.0 (TID 485, 198.202.113.122, executor 7): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=40, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:45 WARN scheduler.TaskSetManager: Lost task 9.0 in stage 14.0 (TID 454, 198.202.119.204, executor 35): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=9, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7276 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:45 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 14.0 (TID 447, 198.202.115.208, executor 1): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:45 WARN scheduler.TaskSetManager: Lost task 22.0 in stage 14.0 (TID 467, 198.202.115.208, executor 1): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=22, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:45 WARN scheduler.TaskSetManager: Lost task 39.0 in stage 14.0 (TID 484, 198.202.119.204, executor 35): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=39, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:45 WARN scheduler.TaskSetManager: Lost task 90.0 in stage 14.0 (TID 535, 198.202.113.204, executor 40): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=90, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7211 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:46 WARN scheduler.TaskSetManager: Lost task 50.0 in stage 14.0 (TID 495, 198.202.113.204, executor 40): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=50, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:46 WARN scheduler.TaskSetManager: Lost task 41.0 in stage 14.0 (TID 486, 198.202.115.133, executor 10): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=41, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7153 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:46 WARN scheduler.TaskSetManager: Lost task 32.0 in stage 14.0 (TID 477, 198.202.115.208, executor 1): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=32, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:46 WARN scheduler.TaskSetManager: Lost task 21.0 in stage 14.0 (TID 466, 198.202.115.208, executor 0): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=21, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:46 WARN scheduler.TaskSetManager: Lost task 81.0 in stage 14.0 (TID 526, 198.202.115.133, executor 10): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=81, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:46 WARN scheduler.TaskSetManager: Lost task 62.0 in stage 14.0 (TID 507, 198.202.115.136, executor 15): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=62, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7231 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:46 WARN scheduler.TaskSetManager: Lost task 29.0 in stage 14.0 (TID 474, 198.202.119.204, executor 35): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=29, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:46 WARN scheduler.TaskSetManager: Lost task 12.0 in stage 14.0 (TID 457, 198.202.115.208, executor 1): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=12, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:47 WARN scheduler.TaskSetManager: Lost task 14.0 in stage 14.0 (TID 459, 198.202.119.204, executor 37): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=14, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:47 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 14.0 (TID 446, 198.202.115.208, executor 0): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=1, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:47 WARN scheduler.TaskSetManager: Lost task 11.0 in stage 14.0 (TID 456, 198.202.115.208, executor 0): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=11, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:48 WARN scheduler.TaskSetManager: Lost task 63.0 in stage 14.0 (TID 508, 198.202.113.122, executor 6): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=63, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:49 WARN scheduler.TaskSetManager: Lost task 73.0 in stage 14.0 (TID 518, 198.202.113.204, executor 44): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=73, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:49 WARN scheduler.TaskSetManager: Lost task 59.0 in stage 14.0 (TID 504, 198.202.115.133, executor 14): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=59, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:50 WARN scheduler.TaskSetManager: Lost task 99.0 in stage 14.0 (TID 544, 198.202.115.133, executor 14): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=99, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7306 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:50 WARN scheduler.TaskSetManager: Lost task 86.0 in stage 14.0 (TID 531, 198.202.115.133, executor 13): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=86, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:50 WARN scheduler.TaskSetManager: Lost task 34.0 in stage 14.0 (TID 479, 198.202.119.204, executor 37): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=34, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7217 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:50 WARN scheduler.TaskSetManager: Lost task 94.0 in stage 14.0 (TID 539, 198.202.113.202, executor 46): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=94, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:50 WARN scheduler.TaskSetManager: Lost task 46.0 in stage 14.0 (TID 491, 198.202.115.133, executor 13): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=46, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:51 WARN scheduler.TaskSetManager: Lost task 83.0 in stage 14.0 (TID 528, 198.202.113.202, executor 47): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=83, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7225 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:51 WARN scheduler.TaskSetManager: Lost task 54.0 in stage 14.0 (TID 499, 198.202.113.202, executor 46): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=54, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7302 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:52 WARN scheduler.TaskSetManager: Lost task 24.0 in stage 14.0 (TID 469, 198.202.119.204, executor 37): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=24, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7164 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:52 WARN scheduler.TaskSetManager: Lost task 43.0 in stage 14.0 (TID 488, 198.202.113.202, executor 47): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=43, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:53 WARN scheduler.TaskSetManager: Lost task 4.0 in stage 14.0 (TID 449, 198.202.119.204, executor 37): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=4, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7228 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:54 WARN scheduler.TaskSetManager: Lost task 87.0 in stage 14.0 (TID 532, 198.202.115.133, executor 11): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=87, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7190 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:54 WARN scheduler.TaskSetManager: Lost task 47.0 in stage 14.0 (TID 492, 198.202.115.133, executor 11): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=47, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:55 WARN scheduler.TaskSetManager: Lost task 76.0 in stage 14.0 (TID 521, 198.202.113.204, executor 42): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=76, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:55 WARN scheduler.TaskSetManager: Lost task 95.0 in stage 14.0 (TID 540, 198.202.113.202, executor 49): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=95, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:25:56 WARN scheduler.TaskSetManager: Lost task 55.0 in stage 14.0 (TID 500, 198.202.113.202, executor 49): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=55, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7255 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:57 WARN scheduler.TaskSetManager: Lost task 88.0 in stage 14.0 (TID 533, 198.202.113.122, executor 8): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=88, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7304 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 12:25:59 WARN scheduler.TaskSetManager: Lost task 48.0 in stage 14.0 (TID 493, 198.202.113.122, executor 8): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=48, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 12:26:00 WARN scheduler.TaskSetManager: Lost task 65.0 in stage 14.0 (TID 510, 198.202.113.202, executor 48): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=9, mapId=1, reduceId=65, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
9579025
**** MultiplySpark run time: 333.392 secs
20/02/06 12:30:07 WARN scheduler.TaskSetManager: Lost task 35.0 in stage 17.0 (TID 685, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=10, mapId=0, reduceId=35, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 12:30:07 WARN scheduler.TaskSetManager: Lost task 9.0 in stage 17.0 (TID 659, 198.202.113.133, executor 31): FetchFailed(null, shuffleId=10, mapId=-1, reduceId=9, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 10
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:30:07 WARN scheduler.TaskSetManager: Lost task 29.0 in stage 17.0 (TID 679, 198.202.113.133, executor 31): FetchFailed(null, shuffleId=10, mapId=-1, reduceId=29, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 10
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:30:07 WARN scheduler.TaskSetManager: Lost task 19.0 in stage 17.0 (TID 669, 198.202.113.133, executor 31): FetchFailed(null, shuffleId=10, mapId=-1, reduceId=19, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 10
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:30:07 WARN scheduler.TaskSetManager: Lost task 39.0 in stage 17.0 (TID 689, 198.202.113.133, executor 31): FetchFailed(null, shuffleId=10, mapId=-1, reduceId=39, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 10
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:30:07 WARN scheduler.TaskSetManager: Lost task 36.0 in stage 17.0 (TID 686, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=10, mapId=0, reduceId=36, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 12:30:08 WARN scheduler.TaskSetManager: Lost task 32.0 in stage 17.0 (TID 682, 198.202.119.204, executor 35): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=10, mapId=0, reduceId=32, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9760 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 39 more

)
20/02/06 12:30:08 WARN scheduler.TaskSetManager: Lost task 7.0 in stage 17.0 (TID 657, 198.202.119.204, executor 36): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=10, mapId=0, reduceId=7, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 12:30:09 WARN scheduler.TaskSetManager: Lost task 34.0 in stage 17.0 (TID 684, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=34, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:30:09 WARN scheduler.TaskSetManager: Lost task 24.0 in stage 17.0 (TID 674, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=24, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:30:09 WARN scheduler.TaskSetManager: Lost task 14.0 in stage 17.0 (TID 664, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=14, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7282 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 31 more

)
20/02/06 12:30:09 WARN scheduler.TaskSetManager: Lost task 4.0 in stage 17.0 (TID 654, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=4, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:06 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 17.0 (TID 655, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=5, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:06 WARN scheduler.TaskSetManager: Lost task 15.0 in stage 17.0 (TID 665, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=15, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:07 WARN scheduler.TaskSetManager: Lost task 40.0 in stage 17.0 (TID 690, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=40, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7293 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 31 more

)
20/02/06 12:31:07 WARN scheduler.TaskSetManager: Lost task 25.0 in stage 17.0 (TID 675, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=25, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7233 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 31 more

)
20/02/06 12:31:09 WARN scheduler.TaskSetManager: Lost task 13.0 in stage 17.0 (TID 663, 198.202.119.204, executor 38): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=13, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:09 WARN scheduler.TaskSetManager: Lost task 33.0 in stage 17.0 (TID 683, 198.202.119.204, executor 38): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=33, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:10 WARN scheduler.TaskSetManager: Lost task 17.0 in stage 17.0 (TID 667, 198.202.119.204, executor 36): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=17, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:10 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 17.0 (TID 653, 198.202.119.204, executor 38): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7770 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 31 more

)
20/02/06 12:31:10 WARN scheduler.TaskSetManager: Lost task 23.0 in stage 17.0 (TID 673, 198.202.119.204, executor 38): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=23, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:11 WARN scheduler.TaskSetManager: Lost task 27.0 in stage 17.0 (TID 677, 198.202.119.204, executor 36): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=27, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:11 WARN scheduler.TaskSetManager: Lost task 37.0 in stage 17.0 (TID 687, 198.202.119.204, executor 36): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=37, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:14 WARN scheduler.TaskSetManager: Lost task 6.0 in stage 17.0 (TID 656, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=6, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:15 WARN scheduler.TaskSetManager: Lost task 26.0 in stage 17.0 (TID 676, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=26, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7214 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 31 more

)
20/02/06 12:31:15 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 17.0 (TID 666, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=16, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:17 WARN scheduler.TaskSetManager: Lost task 8.0 in stage 17.0 (TID 658, 198.202.119.204, executor 39): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=8, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:17 WARN scheduler.TaskSetManager: Lost task 31.0 in stage 17.0 (TID 681, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=31, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:17 WARN scheduler.TaskSetManager: Lost task 11.0 in stage 17.0 (TID 661, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=11, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7230 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 31 more

)
20/02/06 12:31:18 WARN scheduler.TaskSetManager: Lost task 18.0 in stage 17.0 (TID 668, 198.202.119.204, executor 39): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=18, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:19 WARN scheduler.TaskSetManager: Lost task 38.0 in stage 17.0 (TID 688, 198.202.119.204, executor 39): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=38, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:20 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 17.0 (TID 651, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=1, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:20 WARN scheduler.TaskSetManager: Lost task 21.0 in stage 17.0 (TID 671, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=21, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:20 WARN scheduler.TaskSetManager: Lost task 12.0 in stage 17.0 (TID 662, 198.202.119.204, executor 35): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=12, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:21 WARN scheduler.TaskSetManager: Lost task 28.0 in stage 17.0 (TID 678, 198.202.119.204, executor 39): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=28, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:22 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 17.0 (TID 652, 198.202.119.204, executor 35): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:22 WARN scheduler.TaskSetManager: Lost task 22.0 in stage 17.0 (TID 672, 198.202.119.204, executor 35): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=22, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:33 WARN scheduler.TaskSetManager: Lost task 30.0 in stage 17.0 (TID 680, 198.202.119.204, executor 37): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=30, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:37 WARN scheduler.TaskSetManager: Lost task 10.0 in stage 17.0 (TID 660, 198.202.119.204, executor 37): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=10, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:38 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 17.0 (TID 650, 198.202.119.204, executor 37): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=0, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 12:31:39 WARN scheduler.TaskSetManager: Lost task 20.0 in stage 17.0 (TID 670, 198.202.119.204, executor 37): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=11, mapId=0, reduceId=20, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7526 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 31 more

)
9579025
**** MultiplyDiablo run time: 315.41 secs
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 42.0 in stage 20.0 (TID 839, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(38, 198.202.119.204, 36342, None), shuffleId=12, mapId=1, reduceId=42, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 70.0 in stage 20.0 (TID 867, 198.202.113.202, executor 48): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=70, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 69.0 in stage 20.0 (TID 866, 198.202.115.136, executor 19): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=69, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 48.0 in stage 20.0 (TID 845, 198.202.113.122, executor 6): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=48, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 79.0 in stage 20.0 (TID 876, 198.202.115.133, executor 12): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=79, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 88.0 in stage 20.0 (TID 885, 198.202.113.122, executor 6): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=88, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 40.0 in stage 20.0 (TID 837, 198.202.113.204, executor 40): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=40, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 80.0 in stage 20.0 (TID 877, 198.202.113.204, executor 40): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=80, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 76.0 in stage 20.0 (TID 873, 198.202.119.194, executor 29): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=76, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 45.0 in stage 20.0 (TID 842, 198.202.115.133, executor 11): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=45, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 85.0 in stage 20.0 (TID 882, 198.202.115.133, executor 11): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=85, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 74.0 in stage 20.0 (TID 871, 198.202.113.204, executor 43): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=74, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 91.0 in stage 20.0 (TID 888, 198.202.115.136, executor 16): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=91, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 51.0 in stage 20.0 (TID 848, 198.202.115.136, executor 16): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=51, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 72.0 in stage 20.0 (TID 869, 198.202.115.133, executor 13): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=72, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 55.0 in stage 20.0 (TID 852, 198.202.113.133, executor 33): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=55, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 95.0 in stage 20.0 (TID 892, 198.202.113.133, executor 33): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=95, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 96.0 in stage 20.0 (TID 893, 198.202.113.202, executor 45): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=96, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:35:16 WARN scheduler.TaskSetManager: Lost task 56.0 in stage 20.0 (TID 853, 198.202.113.202, executor 45): FetchFailed(null, shuffleId=12, mapId=-1, reduceId=56, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 12
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 12:36:30 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 20.1 (TID 903, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(28, 198.202.119.194, 43193, None), shuffleId=13, mapId=0, reduceId=5, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7196 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
9579025
**** MultiplySpark run time: 374.852 secs
20/02/06 12:42:48 WARN scheduler.TaskSetManager: Lost task 12.0 in stage 23.0 (TID 949, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 42703, None), shuffleId=15, mapId=0, reduceId=12, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7188 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 31 more

)
9579025
**** MultiplyDiablo run time: 361.056 secs
20/02/06 12:46:25 INFO spark.SparkContext: Running Spark version 2.2.0
20/02/06 12:46:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/06 12:46:26 INFO spark.SparkContext: Submitted application: Add
20/02/06 12:46:26 INFO spark.SecurityManager: Changing view acls to: fegaras
20/02/06 12:46:26 INFO spark.SecurityManager: Changing modify acls to: fegaras
20/02/06 12:46:26 INFO spark.SecurityManager: Changing view acls groups to: 
20/02/06 12:46:26 INFO spark.SecurityManager: Changing modify acls groups to: 
20/02/06 12:46:26 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fegaras); groups with view permissions: Set(); users  with modify permissions: Set(fegaras); groups with modify permissions: Set()
20/02/06 12:46:26 INFO util.Utils: Successfully started service 'sparkDriver' on port 33121.
20/02/06 12:46:26 INFO spark.SparkEnv: Registering MapOutputTracker
20/02/06 12:46:26 INFO spark.SparkEnv: Registering BlockManagerMaster
20/02/06 12:46:26 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/06 12:46:26 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/06 12:46:26 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-0b1ae37b-8388-4f62-be34-6c734e506ed1
20/02/06 12:46:26 INFO memory.MemoryStore: MemoryStore started with capacity 12.1 GB
20/02/06 12:46:26 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/02/06 12:46:26 INFO util.log: Logging initialized @1474ms
20/02/06 12:46:26 INFO server.Server: jetty-9.3.z-SNAPSHOT
20/02/06 12:46:26 INFO server.Server: Started @1532ms
20/02/06 12:46:26 INFO server.AbstractConnector: Started ServerConnector@76ab7647{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/02/06 12:46:26 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10027fc9{/jobs,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5489c777{/jobs/json,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62f87c44{/jobs/job,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5149f008{/jobs/job/json,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@158d255c{/stages,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@327120c8{/stages/json,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2b5cb9b2{/stages/stage,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2970a5bc{/stages/stage/json,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@72efb5c1{/stages/pool,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@41200e0c{/stages/pool/json,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4fbdc0f0{/storage,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bc28a83{/storage/json,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@13579834{/storage/rdd,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5bd73d1a{/storage/rdd/json,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2555fff0{/environment,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@120f38e6{/environment/json,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@702ed190{/executors,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7c18432b{/executors/json,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70e29e14{/executors/threadDump,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a4bef8{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2449cff7{/static,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1a15b789{/,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51650883{/api,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@c1fca1e{/jobs/job/kill,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@344344fa{/stages/stage/kill,null,AVAILABLE,@Spark}
20/02/06 12:46:26 INFO ui.SparkUI: Bound SparkUI to comet-22-13.ibnet, and started at http://10.22.250.82:4040
20/02/06 12:46:26 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/lib/diql-spark.jar at spark://10.22.250.82:33121/jars/diql-spark.jar with timestamp 1581021986719
20/02/06 12:46:26 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/benchmarks/diablo/test.jar at spark://10.22.250.82:33121/jars/test.jar with timestamp 1581021986719
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://comet-22-13.ibnet:7077...
20/02/06 12:46:26 INFO client.TransportClientFactory: Successfully created connection to comet-22-13.ibnet/10.22.250.82:7077 after 18 ms (0 ms spent in bootstraps)
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20200206124626-0006
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/0 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/0 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/1 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/1 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/2 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/2 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/3 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/3 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/4 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/4 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/5 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 12:46:26 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38508.
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/5 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/6 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 12:46:26 INFO netty.NettyBlockTransferService: Server created on 10.22.250.82:38508
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/6 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/7 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/7 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/8 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 12:46:26 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/8 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/9 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 12:46:26 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.22.250.82, 38508, None)
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/9 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/10 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/10 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/11 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/11 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/12 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/12 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/13 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 12:46:26 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.22.250.82:38508 with 12.1 GB RAM, BlockManagerId(driver, 10.22.250.82, 38508, None)
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/13 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/14 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/14 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/15 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/15 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/16 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/16 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/17 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 12:46:26 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.22.250.82, 38508, None)
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/17 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.22.250.82, 38508, None)
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/18 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/18 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/19 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/19 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/20 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/20 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/21 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/21 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/22 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/22 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/23 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/23 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/24 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/24 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/25 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/25 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/26 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/26 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/27 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/27 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/28 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/28 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/29 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/29 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/30 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/30 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/31 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/31 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/32 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/32 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/33 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/33 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/34 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/34 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/35 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/35 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/36 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/36 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/37 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/37 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/38 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/38 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/39 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/39 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/40 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/40 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/41 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/41 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/42 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/42 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/43 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/43 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/44 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/44 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/45 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/45 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/46 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/46 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/47 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/47 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/48 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/48 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206124626-0006/49 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 12:46:26 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206124626-0006/49 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/0 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/10 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/1 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/11 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/5 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/15 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/20 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/2 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/12 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/6 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/25 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/21 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/16 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/3 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/13 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/26 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/7 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/22 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/4 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/27 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/35 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/30 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/17 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/14 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/31 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/36 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/45 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/23 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/28 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/37 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/46 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/32 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/18 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/47 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/38 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/40 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/29 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/24 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/41 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/42 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/39 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/8 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/43 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/48 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/19 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/44 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/33 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/49 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/9 is now RUNNING
20/02/06 12:46:26 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206124626-0006/34 is now RUNNING
20/02/06 12:46:27 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@781a9412{/metrics/json,null,AVAILABLE,@Spark}
20/02/06 12:46:27 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
*** 7152 7152  11.05 GB
51136801
**** AddSpark run time: 343.438 secs
51136801
**** AddDiablo run time: 376.518 secs
51136801
**** AddSpark run time: 267.972 secs
51136801
**** AddDiablo run time: 377.651 secs
51136801
**** AddSpark run time: 274.781 secs
51136801
**** AddDiablo run time: 347.637 secs
51136801
**** AddSpark run time: 327.955 secs
51136801
**** AddDiablo run time: 367.335 secs
20/02/06 13:31:11 INFO spark.SparkContext: Running Spark version 2.2.0
20/02/06 13:31:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/06 13:31:12 INFO spark.SparkContext: Submitted application: Multiply
20/02/06 13:31:12 INFO spark.SecurityManager: Changing view acls to: fegaras
20/02/06 13:31:12 INFO spark.SecurityManager: Changing modify acls to: fegaras
20/02/06 13:31:12 INFO spark.SecurityManager: Changing view acls groups to: 
20/02/06 13:31:12 INFO spark.SecurityManager: Changing modify acls groups to: 
20/02/06 13:31:12 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fegaras); groups with view permissions: Set(); users  with modify permissions: Set(fegaras); groups with modify permissions: Set()
20/02/06 13:31:12 INFO util.Utils: Successfully started service 'sparkDriver' on port 46160.
20/02/06 13:31:12 INFO spark.SparkEnv: Registering MapOutputTracker
20/02/06 13:31:12 INFO spark.SparkEnv: Registering BlockManagerMaster
20/02/06 13:31:12 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/06 13:31:12 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/06 13:31:12 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-a56a37e8-3916-4841-9d0c-7d7eba8f6d5c
20/02/06 13:31:12 INFO memory.MemoryStore: MemoryStore started with capacity 12.1 GB
20/02/06 13:31:12 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/02/06 13:31:12 INFO util.log: Logging initialized @1468ms
20/02/06 13:31:12 INFO server.Server: jetty-9.3.z-SNAPSHOT
20/02/06 13:31:12 INFO server.Server: Started @1534ms
20/02/06 13:31:12 INFO server.AbstractConnector: Started ServerConnector@2df0cd7a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/02/06 13:31:12 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@10027fc9{/jobs,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5489c777{/jobs/json,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62f87c44{/jobs/job,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5149f008{/jobs/job/json,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@158d255c{/stages,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@327120c8{/stages/json,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2b5cb9b2{/stages/stage,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2970a5bc{/stages/stage/json,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@72efb5c1{/stages/pool,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@41200e0c{/stages/pool/json,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4fbdc0f0{/storage,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bc28a83{/storage/json,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@13579834{/storage/rdd,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5bd73d1a{/storage/rdd/json,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2555fff0{/environment,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@120f38e6{/environment/json,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@702ed190{/executors,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7c18432b{/executors/json,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70e29e14{/executors/threadDump,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a4bef8{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2449cff7{/static,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1a15b789{/,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51650883{/api,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@c1fca1e{/jobs/job/kill,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@344344fa{/stages/stage/kill,null,AVAILABLE,@Spark}
20/02/06 13:31:12 INFO ui.SparkUI: Bound SparkUI to comet-22-13.ibnet, and started at http://10.22.250.82:4040
20/02/06 13:31:12 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/lib/diql-spark.jar at spark://10.22.250.82:46160/jars/diql-spark.jar with timestamp 1581024672888
20/02/06 13:31:12 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/benchmarks/diablo/test.jar at spark://10.22.250.82:46160/jars/test.jar with timestamp 1581024672889
20/02/06 13:31:12 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://comet-22-13.ibnet:7077...
20/02/06 13:31:12 INFO client.TransportClientFactory: Successfully created connection to comet-22-13.ibnet/10.22.250.82:7077 after 18 ms (0 ms spent in bootstraps)
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20200206133113-0007
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/0 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/0 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/1 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/1 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/2 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/2 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/3 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/3 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43579.
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/4 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 13:31:13 INFO netty.NettyBlockTransferService: Server created on 10.22.250.82:43579
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/4 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/5 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/5 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/6 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 13:31:13 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/6 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/7 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/7 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/8 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/8 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/9 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 13:31:13 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.22.250.82, 43579, None)
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/9 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/10 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/10 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/11 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/11 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/12 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/12 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/13 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/13 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.22.250.82:43579 with 12.1 GB RAM, BlockManagerId(driver, 10.22.250.82, 43579, None)
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/14 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/14 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/15 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/15 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/16 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/16 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/17 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/17 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/18 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 13:31:13 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.22.250.82, 43579, None)
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/18 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/19 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 13:31:13 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.22.250.82, 43579, None)
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/19 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/20 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/20 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/21 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/21 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/22 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/22 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/23 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/23 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/24 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/24 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/25 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/25 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/26 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/26 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/27 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/27 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/28 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/28 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/29 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/29 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/30 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/30 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/31 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/31 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/32 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/32 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/33 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/33 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/34 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/34 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/35 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/35 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/36 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/36 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/37 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/37 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/38 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/38 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/39 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/39 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/40 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/40 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/41 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/41 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/42 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/42 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/43 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/43 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/44 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/44 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/45 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/45 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/46 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/46 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/47 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/47 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/48 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/48 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206133113-0007/49 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206133113-0007/49 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/0 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/10 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/1 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/15 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/30 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/25 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/11 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/2 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/35 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/31 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/20 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/16 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/26 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/36 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/12 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/32 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/3 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/21 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/17 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/5 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/27 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/13 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/4 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/45 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/33 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/40 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/37 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/6 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/22 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/28 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/46 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/14 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/38 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/18 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/41 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/47 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/23 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/42 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/7 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/39 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/29 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/48 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/8 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/34 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/43 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/24 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/49 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/9 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/44 is now RUNNING
20/02/06 13:31:13 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206133113-0007/19 is now RUNNING
20/02/06 13:31:13 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@781a9412{/metrics/json,null,AVAILABLE,@Spark}
20/02/06 13:31:13 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
*** 3576 3576  2.76 GB
12780625
**** MultiplySpark run time: 443.05 secs
20/02/06 13:42:20 WARN scheduler.TaskSetManager: Lost task 46.0 in stage 5.0 (TID 154, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(7, 198.202.113.122, 35106, None), shuffleId=3, mapId=1, reduceId=46, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 13:42:20 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_3_1 !
20/02/06 13:42:20 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1_0 !
20/02/06 13:42:20 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1_1 !
20/02/06 13:42:20 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_3_0 !
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 5.1 (TID 217, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=5, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 15.0 in stage 5.1 (TID 227, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=15, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 24.0 in stage 5.1 (TID 236, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=26, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 27.0 in stage 5.1 (TID 239, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=31, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 29.0 in stage 5.1 (TID 241, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=38, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 5.1 (TID 212, 198.202.115.205, executor 22): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=0, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 10.0 in stage 5.1 (TID 222, 198.202.115.205, executor 22): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=10, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 20.0 in stage 5.1 (TID 232, 198.202.115.205, executor 22): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=21, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 13.0 in stage 5.1 (TID 225, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=13, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 7.0 in stage 5.1 (TID 219, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=7, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 17.0 in stage 5.1 (TID 229, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=17, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 28.0 in stage 5.1 (TID 240, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=34, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9750 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 39 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 25.0 in stage 5.1 (TID 237, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=27, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9669 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 39 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 22.0 in stage 5.1 (TID 234, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=24, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 12.0 in stage 5.1 (TID 224, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=12, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 23.0 in stage 5.1 (TID 235, 198.202.113.133, executor 31): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=25, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9776 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 39 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 14.0 in stage 5.1 (TID 226, 198.202.113.133, executor 31): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=14, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 4.0 in stage 5.1 (TID 216, 198.202.113.133, executor 31): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=4, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9710 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 39 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 18.0 in stage 5.1 (TID 230, 198.202.115.205, executor 24): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=18, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 8.0 in stage 5.1 (TID 220, 198.202.115.205, executor 24): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=8, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 5.1 (TID 215, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=2, mapId=0, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9955 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 39 more

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 5.1 (TID 228, 198.202.115.205, executor 23): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=16, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 6.0 in stage 5.1 (TID 218, 198.202.115.205, executor 23): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=6, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 11.0 in stage 5.1 (TID 223, 198.202.115.205, executor 21): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=11, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 13:44:01 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 5.1 (TID 213, 198.202.115.205, executor 21): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=1, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 13:44:07 WARN scheduler.TaskSetManager: Lost task 9.0 in stage 5.1 (TID 221, 198.202.115.205, executor 20): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=9, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 13:44:07 WARN scheduler.TaskSetManager: Lost task 19.0 in stage 5.1 (TID 231, 198.202.115.205, executor 20): FetchFailed(null, shuffleId=2, mapId=-1, reduceId=19, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 2
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:697)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:693)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:693)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:147)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:49)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

)
20/02/06 13:44:15 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 3.2 (TID 242, 198.202.115.205, executor 22): java.io.StreamCorruptedException: invalid type code: F1
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1754)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2041)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1572)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:430)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream$$anon$1.getNext(Serializer.scala:168)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:148)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

12780625
**** MultiplyDiablo run time: 638.697 secs
20/02/06 13:52:22 WARN scheduler.TaskSetManager: Lost task 48.0 in stage 8.0 (TID 297, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(3, 198.202.115.208, 37394, None), shuffleId=5, mapId=1, reduceId=48, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:54:22 WARN scheduler.TaskSetManager: Lost task 66.0 in stage 8.1 (TID 416, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=83, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:54:22 WARN scheduler.TaskSetManager: Lost task 26.0 in stage 8.1 (TID 376, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=26, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7636 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:55:53 WARN scheduler.TaskSetManager: Lost task 29.0 in stage 8.1 (TID 379, 198.202.119.204, executor 37): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=29, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:55:54 WARN scheduler.TaskSetManager: Lost task 21.0 in stage 8.1 (TID 371, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=21, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7220 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:55:55 WARN scheduler.TaskSetManager: Lost task 69.0 in stage 8.1 (TID 419, 198.202.119.204, executor 37): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=89, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:55:55 WARN scheduler.TaskSetManager: Lost task 61.0 in stage 8.1 (TID 411, 198.202.113.133, executor 30): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=74, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:55:56 WARN scheduler.TaskSetManager: Lost task 57.0 in stage 8.1 (TID 407, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=64, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:55:57 WARN scheduler.TaskSetManager: Lost task 35.0 in stage 8.1 (TID 385, 198.202.115.208, executor 0): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=35, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:55:58 WARN scheduler.TaskSetManager: Lost task 17.0 in stage 8.1 (TID 367, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(29, 198.202.119.194, 40991, None), shuffleId=5, mapId=0, reduceId=17, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:55:58 WARN scheduler.TaskSetManager: Lost task 32.0 in stage 8.1 (TID 382, 198.202.115.208, executor 2): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=32, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:55:58 WARN scheduler.TaskSetManager: Lost task 25.0 in stage 8.1 (TID 375, 198.202.119.194, executor 25): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=25, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:55:58 WARN scheduler.TaskSetManager: Lost task 47.0 in stage 8.1 (TID 397, 198.202.119.194, executor 28): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=50, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7205 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:55:58 WARN scheduler.TaskSetManager: Lost task 36.0 in stage 8.1 (TID 386, 198.202.115.208, executor 1): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=36, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:55:58 WARN scheduler.TaskSetManager: Lost task 65.0 in stage 8.1 (TID 415, 198.202.119.194, executor 25): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=82, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:55:59 WARN scheduler.TaskSetManager: Lost task 76.0 in stage 8.1 (TID 426, 198.202.115.208, executor 1): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=98, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:55:59 WARN scheduler.TaskSetManager: Lost task 67.0 in stage 8.1 (TID 417, 198.202.113.133, executor 31): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=85, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:55:59 WARN scheduler.TaskSetManager: Lost task 72.0 in stage 8.1 (TID 422, 198.202.115.208, executor 2): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=93, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:00 WARN scheduler.TaskSetManager: Lost task 40.0 in stage 8.1 (TID 390, 198.202.119.194, executor 29): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=41, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:01 WARN scheduler.TaskSetManager: Lost task 34.0 in stage 8.1 (TID 384, 198.202.119.194, executor 27): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=34, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7207 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:56:01 WARN scheduler.TaskSetManager: Lost task 38.0 in stage 8.1 (TID 388, 198.202.119.194, executor 26): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=38, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7410 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:56:01 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 8.1 (TID 366, 198.202.119.204, executor 38): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=16, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7185 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:56:02 WARN scheduler.TaskSetManager: Lost task 56.0 in stage 8.1 (TID 406, 198.202.119.204, executor 38): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=63, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7781 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:56:02 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 8.1 (TID 353, 198.202.115.208, executor 4): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:02 WARN scheduler.TaskSetManager: Lost task 43.0 in stage 8.1 (TID 393, 198.202.115.208, executor 4): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=44, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:03 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 8.1 (TID 355, 198.202.119.204, executor 36): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=5, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:05 WARN scheduler.TaskSetManager: Lost task 63.0 in stage 8.1 (TID 413, 198.202.119.204, executor 35): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=77, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:06 WARN scheduler.TaskSetManager: Lost task 23.0 in stage 8.1 (TID 373, 198.202.119.204, executor 35): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=23, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:08 WARN scheduler.TaskSetManager: Lost task 45.0 in stage 8.1 (TID 395, 198.202.119.204, executor 36): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=48, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:09 WARN scheduler.TaskSetManager: Lost task 70.0 in stage 8.1 (TID 420, 198.202.119.204, executor 39): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=90, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:10 WARN scheduler.TaskSetManager: Lost task 62.0 in stage 8.1 (TID 412, 198.202.113.204, executor 42): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=76, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:12 WARN scheduler.TaskSetManager: Lost task 22.0 in stage 8.1 (TID 372, 198.202.113.204, executor 42): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=22, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:13 WARN scheduler.TaskSetManager: Lost task 20.0 in stage 8.1 (TID 370, 198.202.113.202, executor 45): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=20, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:14 WARN scheduler.TaskSetManager: Lost task 60.0 in stage 8.1 (TID 410, 198.202.113.202, executor 45): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=73, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:15 WARN scheduler.TaskSetManager: Lost task 9.0 in stage 8.1 (TID 359, 198.202.115.133, executor 11): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=9, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7220 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:56:15 WARN scheduler.TaskSetManager: Lost task 52.0 in stage 8.1 (TID 402, 198.202.113.204, executor 43): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=57, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7151 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:56:17 WARN scheduler.TaskSetManager: Lost task 71.0 in stage 8.1 (TID 421, 198.202.113.204, executor 44): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=92, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:17 WARN scheduler.TaskSetManager: Lost task 12.0 in stage 8.1 (TID 362, 198.202.113.204, executor 43): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=12, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:17 WARN scheduler.TaskSetManager: Lost task 51.0 in stage 8.1 (TID 401, 198.202.115.208, executor 3): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=56, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:20 WARN scheduler.TaskSetManager: Lost task 39.0 in stage 8.1 (TID 389, 198.202.115.133, executor 14): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=39, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:21 WARN scheduler.TaskSetManager: Lost task 77.0 in stage 8.1 (TID 427, 198.202.115.136, executor 16): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=99, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:23 WARN scheduler.TaskSetManager: Lost task 8.0 in stage 8.1 (TID 358, 198.202.113.202, executor 49): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=8, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:24 WARN scheduler.TaskSetManager: Lost task 50.0 in stage 8.1 (TID 400, 198.202.115.133, executor 10): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=55, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:25 WARN scheduler.TaskSetManager: Lost task 15.0 in stage 8.1 (TID 365, 198.202.113.204, executor 41): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=15, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:28 WARN scheduler.TaskSetManager: Lost task 46.0 in stage 8.1 (TID 396, 198.202.113.202, executor 47): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=49, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7194 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:56:28 WARN scheduler.TaskSetManager: Lost task 6.0 in stage 8.1 (TID 356, 198.202.113.202, executor 47): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=6, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:29 WARN scheduler.TaskSetManager: Lost task 44.0 in stage 8.1 (TID 394, 198.202.115.136, executor 18): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=45, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7203 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:56:29 WARN scheduler.TaskSetManager: Lost task 42.0 in stage 8.1 (TID 392, 198.202.115.133, executor 13): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=43, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:31 WARN scheduler.TaskSetManager: Lost task 4.0 in stage 8.1 (TID 354, 198.202.115.136, executor 18): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=4, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7280 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:56:31 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 8.1 (TID 352, 198.202.115.133, executor 13): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:31 WARN scheduler.TaskSetManager: Lost task 53.0 in stage 8.1 (TID 403, 198.202.115.136, executor 15): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=58, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7163 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:56:31 WARN scheduler.TaskSetManager: Lost task 13.0 in stage 8.1 (TID 363, 198.202.115.136, executor 15): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=13, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:35 WARN scheduler.TaskSetManager: Lost task 19.0 in stage 8.1 (TID 369, 198.202.115.136, executor 19): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=19, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:42 WARN scheduler.TaskSetManager: Lost task 59.0 in stage 8.1 (TID 409, 198.202.115.136, executor 19): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=71, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7198 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 28 more

)
20/02/06 13:56:51 WARN scheduler.TaskSetManager: Lost task 58.0 in stage 8.1 (TID 408, 198.202.113.204, executor 40): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=69, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
20/02/06 13:56:53 WARN scheduler.TaskSetManager: Lost task 18.0 in stage 8.1 (TID 368, 198.202.113.204, executor 40): FetchFailed(BlockManagerId(33, 198.202.113.133, 44265, None), shuffleId=5, mapId=1, reduceId=18, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
12780625
**** MultiplySpark run time: 552.056 secs
20/02/06 14:02:33 WARN scheduler.TaskSetManager: Lost task 19.0 in stage 11.0 (TID 453, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(3, 198.202.115.208, 37394, None), shuffleId=7, mapId=1, reduceId=19, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 7205 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 31 more

)
20/02/06 14:06:18 WARN scheduler.TaskSetManager: Lost task 15.0 in stage 11.1 (TID 550, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(17, 198.202.115.136, 44181, None), shuffleId=7, mapId=1, reduceId=99, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 14:06:27 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 11.1 (TID 535, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(17, 198.202.115.136, 44181, None), shuffleId=7, mapId=1, reduceId=5, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
12780625
**** MultiplyDiablo run time: 542.2 secs
20/02/06 14:09:09 WARN scheduler.TaskSetManager: Lost task 21.0 in stage 14.0 (TID 577, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(7, 198.202.113.122, 35106, None), shuffleId=8, mapId=1, reduceId=21, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
20/02/06 14:09:09 WARN scheduler.TaskSetManager: Lost task 37.0 in stage 14.0 (TID 593, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=8, mapId=0, reduceId=37, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
20/02/06 14:09:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1_0 !
20/02/06 14:09:09 WARN scheduler.TaskSetManager: Lost task 38.0 in stage 14.0 (TID 594, 198.202.113.122, executor 8): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=8, mapId=0, reduceId=38, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
20/02/06 14:09:09 WARN scheduler.TaskSetManager: Lost task 33.0 in stage 14.0 (TID 589, 198.202.113.122, executor 9): FetchFailed(BlockManagerId(32, 198.202.113.133, 33486, None), shuffleId=8, mapId=0, reduceId=33, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 28 more

)
12780625
**** MultiplySpark run time: 475.914 secs
20/02/06 14:18:45 WARN scheduler.TaskSetManager: Lost task 88.0 in stage 17.0 (TID 792, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(3, 198.202.115.208, 37394, None), shuffleId=11, mapId=1, reduceId=88, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
12780625
**** MultiplyDiablo run time: 549.602 secs
20/02/06 14:27:41 WARN scheduler.TaskSetManager: Lost task 66.0 in stage 20.0 (TID 961, 198.202.113.133, executor 33): FetchFailed(BlockManagerId(3, 198.202.115.208, 37394, None), shuffleId=13, mapId=1, reduceId=66, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 20 more

)
12780625
**** MultiplySpark run time: 502.604 secs
20/02/06 14:34:47 WARN scheduler.TaskSetManager: Lost task 22.0 in stage 23.0 (TID 1105, 198.202.113.133, executor 34): FetchFailed(BlockManagerId(7, 198.202.113.122, 35106, None), shuffleId=14, mapId=1, reduceId=22, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 31 more

)
20/02/06 14:34:48 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 23.0 (TID 1086, 198.202.113.133, executor 32): FetchFailed(BlockManagerId(29, 198.202.119.194, 40991, None), shuffleId=15, mapId=0, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: Stream is corrupted
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:403)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:59)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:40)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:137)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply$mcJ$sp(Utils.scala:340)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$$anonfun$copyStream$1.apply(Utils.scala:327)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337)
	at org.apache.spark.util.Utils$.copyStream(Utils.scala:348)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:395)
	... 23 more

)
20/02/06 14:34:48 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_3_0 !
12780625
**** MultiplyDiablo run time: 602.278 secs
20/02/06 14:43:09 INFO spark.SparkContext: Running Spark version 2.2.0
20/02/06 14:43:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/06 14:43:09 INFO spark.SparkContext: Submitted application: Add
20/02/06 14:43:09 INFO spark.SecurityManager: Changing view acls to: fegaras
20/02/06 14:43:09 INFO spark.SecurityManager: Changing modify acls to: fegaras
20/02/06 14:43:09 INFO spark.SecurityManager: Changing view acls groups to: 
20/02/06 14:43:09 INFO spark.SecurityManager: Changing modify acls groups to: 
20/02/06 14:43:09 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fegaras); groups with view permissions: Set(); users  with modify permissions: Set(fegaras); groups with modify permissions: Set()
20/02/06 14:43:10 INFO util.Utils: Successfully started service 'sparkDriver' on port 37528.
20/02/06 14:43:10 INFO spark.SparkEnv: Registering MapOutputTracker
20/02/06 14:43:10 INFO spark.SparkEnv: Registering BlockManagerMaster
20/02/06 14:43:10 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/06 14:43:10 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/06 14:43:10 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-ea348e83-3065-4bb3-90cc-e1fab2da062e
20/02/06 14:43:10 INFO memory.MemoryStore: MemoryStore started with capacity 12.1 GB
20/02/06 14:43:10 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/02/06 14:43:10 INFO util.log: Logging initialized @4545ms
20/02/06 14:43:10 INFO server.Server: jetty-9.3.z-SNAPSHOT
20/02/06 14:43:10 INFO server.Server: Started @4610ms
20/02/06 14:43:10 INFO server.AbstractConnector: Started ServerConnector@17ca31c9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/02/06 14:43:10 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54afd745{/jobs,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3676ac27{/jobs/json,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@48f5bde6{/jobs/job,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7072bc39{/jobs/job/json,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ca65ce4{/stages,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5707c1cb{/stages/json,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35038141{/stages/stage,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@50305a{/stages/stage/json,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d511b5f{/stages/pool,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40f33492{/stages/pool/json,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ad3a1bb{/storage,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@324c64cd{/storage/json,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@24be2d9c{/storage/rdd,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@aec50a1{/storage/rdd/json,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70d2e40b{/environment,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a0e1b5e{/environment/json,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@173b9122{/executors,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7646731d{/executors/json,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3b1bb3ab{/executors/threadDump,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40bffbca{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@42a9a63e{/static,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@57f791c6{/,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6c4f9535{/api,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@241a53ef{/jobs/job/kill,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2db2cd5{/stages/stage/kill,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO ui.SparkUI: Bound SparkUI to comet-22-13.ibnet, and started at http://10.22.250.82:4040
20/02/06 14:43:10 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/lib/diql-spark.jar at spark://10.22.250.82:37528/jars/diql-spark.jar with timestamp 1581028990414
20/02/06 14:43:10 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/benchmarks/diablo/test.jar at spark://10.22.250.82:37528/jars/test.jar with timestamp 1581028990415
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://comet-22-13.ibnet:7077...
20/02/06 14:43:10 INFO client.TransportClientFactory: Successfully created connection to comet-22-13.ibnet/10.22.250.82:7077 after 20 ms (0 ms spent in bootstraps)
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20200206144310-0008
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/0 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/0 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/1 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/1 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/2 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/2 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/3 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/3 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/4 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/4 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/5 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 14:43:10 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45470.
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/5 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/6 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 14:43:10 INFO netty.NettyBlockTransferService: Server created on 10.22.250.82:45470
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/6 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/7 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/7 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/8 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/8 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/9 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/9 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/10 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/10 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/11 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/11 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/12 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 14:43:10 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.22.250.82, 45470, None)
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/12 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/13 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/13 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/14 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/14 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/15 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/15 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/16 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/16 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.22.250.82:45470 with 12.1 GB RAM, BlockManagerId(driver, 10.22.250.82, 45470, None)
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/17 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/17 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/18 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/18 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/19 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/19 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/20 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/20 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.22.250.82, 45470, None)
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/21 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/21 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.22.250.82, 45470, None)
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/22 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/22 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/23 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/23 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/24 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/24 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/25 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/25 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/26 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/26 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/27 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/27 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/28 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/28 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/29 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/29 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/30 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/30 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/31 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/31 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/32 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/32 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/33 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/33 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/34 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/34 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/35 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/35 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/36 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/36 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/37 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/37 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/38 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/38 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/39 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/39 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/40 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/40 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/41 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/41 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/42 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/42 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/43 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/43 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/44 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/44 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/45 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/45 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/46 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/46 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/47 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/47 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/48 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/48 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206144310-0008/49 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206144310-0008/49 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/0 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/10 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/5 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/1 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/15 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/20 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/11 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/6 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/25 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/2 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/21 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/12 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/30 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/35 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/3 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/7 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/16 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/26 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/13 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/31 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/40 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/22 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/36 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/4 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/27 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/45 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/8 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/41 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/32 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/14 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/37 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/46 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/23 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/28 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/9 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/47 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/42 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/33 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/38 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/29 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/24 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/17 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/39 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/48 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/43 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/34 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/44 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/49 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/18 is now RUNNING
20/02/06 14:43:10 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206144310-0008/19 is now RUNNING
20/02/06 14:43:10 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a4c638d{/metrics/json,null,AVAILABLE,@Spark}
20/02/06 14:43:10 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
*** 8000 8000  13.83 GB
63984001
**** AddSpark run time: 573.68 secs
63984001
**** AddDiablo run time: 481.932 secs
63984001
**** AddSpark run time: 431.154 secs
63984001
**** AddDiablo run time: 527.711 secs
63984001
**** AddSpark run time: 361.25 secs
63984001
**** AddDiablo run time: 496.331 secs
63984001
**** AddSpark run time: 448.389 secs
63984001
**** AddDiablo run time: 471.554 secs
20/02/06 15:46:25 INFO spark.SparkContext: Running Spark version 2.2.0
20/02/06 15:46:26 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/06 15:46:26 INFO spark.SparkContext: Submitted application: Multiply
20/02/06 15:46:26 INFO spark.SecurityManager: Changing view acls to: fegaras
20/02/06 15:46:26 INFO spark.SecurityManager: Changing modify acls to: fegaras
20/02/06 15:46:26 INFO spark.SecurityManager: Changing view acls groups to: 
20/02/06 15:46:26 INFO spark.SecurityManager: Changing modify acls groups to: 
20/02/06 15:46:26 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fegaras); groups with view permissions: Set(); users  with modify permissions: Set(fegaras); groups with modify permissions: Set()
20/02/06 15:46:26 INFO util.Utils: Successfully started service 'sparkDriver' on port 35459.
20/02/06 15:46:26 INFO spark.SparkEnv: Registering MapOutputTracker
20/02/06 15:46:26 INFO spark.SparkEnv: Registering BlockManagerMaster
20/02/06 15:46:26 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/06 15:46:26 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/06 15:46:26 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-a78cbecc-5414-4e71-9085-91b4a4cb4204
20/02/06 15:46:26 INFO memory.MemoryStore: MemoryStore started with capacity 12.1 GB
20/02/06 15:46:26 INFO spark.SparkEnv: Registering OutputCommitCoordinator
20/02/06 15:46:26 INFO util.log: Logging initialized @1503ms
20/02/06 15:46:26 INFO server.Server: jetty-9.3.z-SNAPSHOT
20/02/06 15:46:26 INFO server.Server: Started @1567ms
20/02/06 15:46:26 INFO server.AbstractConnector: Started ServerConnector@63f34b70{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
20/02/06 15:46:26 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@fff25f1{/jobs,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@48f5bde6{/jobs/json,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5149f008{/jobs/job,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ca65ce4{/jobs/job/json,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5707c1cb{/stages,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35038141{/stages/json,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@672f11c2{/stages/stage,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d511b5f{/stages/stage/json,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40f33492{/stages/pool,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ad3a1bb{/stages/pool/json,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@324c64cd{/storage,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@24be2d9c{/storage/json,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@aec50a1{/storage/rdd,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70d2e40b{/storage/rdd/json,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a0e1b5e{/environment,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@173b9122{/environment/json,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7646731d{/executors,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3b1bb3ab{/executors/json,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40bffbca{/executors/threadDump,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@42a9a63e{/executors/threadDump/json,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5d8445d7{/static,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6c4f9535{/,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30c31dd7{/api,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2db2cd5{/jobs/job/kill,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@615f972{/stages/stage/kill,null,AVAILABLE,@Spark}
20/02/06 15:46:26 INFO ui.SparkUI: Bound SparkUI to comet-22-13.ibnet, and started at http://10.22.250.82:4040
20/02/06 15:46:26 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/lib/diql-spark.jar at spark://10.22.250.82:35459/jars/diql-spark.jar with timestamp 1581032786959
20/02/06 15:46:26 INFO spark.SparkContext: Added JAR file:/oasis/projects/nsf/uot143/fegaras/diql/benchmarks/diablo/test.jar at spark://10.22.250.82:35459/jars/test.jar with timestamp 1581032786959
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://comet-22-13.ibnet:7077...
20/02/06 15:46:27 INFO client.TransportClientFactory: Successfully created connection to comet-22-13.ibnet/10.22.250.82:7077 after 18 ms (0 ms spent in bootstraps)
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20200206154627-0009
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/0 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/0 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/1 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/1 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/2 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/2 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/3 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/3 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35858.
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/4 on worker-20200206103310-198.202.115.208-38190 (198.202.115.208:38190) with 4 cores
20/02/06 15:46:27 INFO netty.NettyBlockTransferService: Server created on 10.22.250.82:35858
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/4 on hostPort 198.202.115.208:38190 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/5 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/5 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/6 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 15:46:27 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/6 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/7 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/7 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/8 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/8 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/9 on worker-20200206103306-198.202.113.122-32950 (198.202.113.122:32950) with 4 cores
20/02/06 15:46:27 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.22.250.82, 35858, None)
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/9 on hostPort 198.202.113.122:32950 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/10 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/10 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/11 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/11 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/12 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/12 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/13 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 15:46:27 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.22.250.82:35858 with 12.1 GB RAM, BlockManagerId(driver, 10.22.250.82, 35858, None)
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/13 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/14 on worker-20200206103307-198.202.115.133-45097 (198.202.115.133:45097) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/14 on hostPort 198.202.115.133:45097 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/15 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/15 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/16 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/16 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/17 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 15:46:27 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.22.250.82, 35858, None)
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/17 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/18 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 15:46:27 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.22.250.82, 35858, None)
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/18 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/19 on worker-20200206103307-198.202.115.136-34247 (198.202.115.136:34247) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/19 on hostPort 198.202.115.136:34247 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/20 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/20 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/21 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/21 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/22 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/22 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/23 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/23 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/24 on worker-20200206103307-198.202.115.205-38368 (198.202.115.205:38368) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/24 on hostPort 198.202.115.205:38368 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/25 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/25 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/26 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/26 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/27 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/27 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/28 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/28 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/29 on worker-20200206103306-198.202.119.194-44983 (198.202.119.194:44983) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/29 on hostPort 198.202.119.194:44983 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/30 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/30 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/31 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/31 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/32 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/32 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/33 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/33 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/34 on worker-20200206103310-198.202.113.133-36029 (198.202.113.133:36029) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/34 on hostPort 198.202.113.133:36029 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/35 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/35 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/36 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/36 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/37 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/37 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/38 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/38 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/39 on worker-20200206103306-198.202.119.204-40734 (198.202.119.204:40734) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/39 on hostPort 198.202.119.204:40734 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/40 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/40 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/41 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/41 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/42 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/42 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/43 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/43 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/44 on worker-20200206103307-198.202.113.204-45280 (198.202.113.204:45280) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/44 on hostPort 198.202.113.204:45280 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/45 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/45 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/46 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/46 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/47 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/47 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/48 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/48 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20200206154627-0009/49 on worker-20200206103307-198.202.113.202-39510 (198.202.113.202:39510) with 4 cores
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20200206154627-0009/49 on hostPort 198.202.113.202:39510 with 4 cores, 23.0 GB RAM
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/10 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/15 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/20 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/30 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/25 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/11 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/16 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/35 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/45 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/31 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/12 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/26 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/40 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/21 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/0 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/17 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/1 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/46 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/41 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/32 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/13 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/22 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/36 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/5 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/2 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/47 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/18 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/42 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/6 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/37 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/48 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/23 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/3 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/33 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/7 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/38 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/49 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/14 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/43 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/19 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/39 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/24 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/8 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/44 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/34 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/9 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/4 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/27 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/28 is now RUNNING
20/02/06 15:46:27 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20200206154627-0009/29 is now RUNNING
20/02/06 15:46:27 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@aed0151{/metrics/json,null,AVAILABLE,@Spark}
20/02/06 15:46:27 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
*** 4000 4000  3.46 GB
15992001
**** MultiplySpark run time: 559.47 secs
20/02/06 15:58:17 WARN scheduler.TaskSetManager: Lost task 68.0 in stage 5.0 (TID 176, 198.202.113.133, executor 31): java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:479)
	at java.io.ObjectInputStream$PeekInputStream.read(ObjectInputStream.java:2662)
	at java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2678)
	at java.io.ObjectInputStream$BlockDataInputStream.readInt(ObjectInputStream.java:3179)
	at java.io.ObjectInputStream.readHandle(ObjectInputStream.java:1683)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1552)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:430)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readKey(Serializer.scala:156)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:188)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

15992001
**** MultiplyDiablo run time: 548.537 secs
20/02/06 16:07:02 WARN scheduler.TaskSetManager: Lost task 50.0 in stage 8.0 (TID 263, 198.202.113.133, executor 33): java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:479)
	at java.io.ObjectInputStream$PeekInputStream.read(ObjectInputStream.java:2662)
	at java.io.ObjectInputStream$BlockDataInputStream.read(ObjectInputStream.java:3079)
	at java.io.ObjectInputStream$BlockDataInputStream.readFully(ObjectInputStream.java:3103)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2275)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2210)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2068)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1572)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2286)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2210)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2068)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1572)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2286)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2210)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2068)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1572)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:430)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:158)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:188)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

15992001
**** MultiplySpark run time: 530.845 secs
15992001
**** MultiplyDiablo run time: 530.187 secs
20/02/06 16:24:46 WARN scheduler.TaskSetManager: Lost task 53.0 in stage 14.0 (TID 475, 198.202.113.133, executor 34): java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:220)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:115)
	at org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:459)
	at java.io.ObjectInputStream$PeekInputStream.peek(ObjectInputStream.java:2640)
	at java.io.ObjectInputStream$BlockDataInputStream.peek(ObjectInputStream.java:2947)
	at java.io.ObjectInputStream$BlockDataInputStream.peekByte(ObjectInputStream.java:2957)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1539)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2286)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2210)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2068)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1572)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:430)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:158)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:188)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

15992001
**** MultiplySpark run time: 545.305 secs
20/02/06 16:34:12 WARN scheduler.TaskSetManager: Lost task 38.0 in stage 17.0 (TID 565, 198.202.113.133, executor 34): java.io.IOException: Stream is corrupted
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:211)
	at org.apache.spark.io.LZ4BlockInputStream.read(LZ4BlockInputStream.java:125)
	at org.apache.spark.storage.BufferReleasingInputStream.read(ShuffleBlockFetcherIterator.scala:479)
	at java.io.ObjectInputStream$PeekInputStream.read(ObjectInputStream.java:2662)
	at java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2678)
	at java.io.ObjectInputStream$BlockDataInputStream.readInt(ObjectInputStream.java:3179)
	at java.io.ObjectInputStream.readHandle(ObjectInputStream.java:1683)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1744)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2041)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1572)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2286)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2210)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2068)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1572)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2286)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2210)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2068)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1572)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:430)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:158)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:188)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:183)
	at scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1336)
	at scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:294)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1336)
	at edu.uta.diql.core.GroupByJoin$.edu$uta$diql$core$GroupByJoin$$combine$1(SparkCodeGererator.scala:39)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at edu.uta.diql.core.GroupByJoin$$anonfun$groupByJoin$1.apply(SparkCodeGererator.scala:64)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: net.jpountz.lz4.LZ4Exception: Error decoding offset 9784 of input buffer
	at net.jpountz.lz4.LZ4JNIFastDecompressor.decompress(LZ4JNIFastDecompressor.java:39)
	at org.apache.spark.io.LZ4BlockInputStream.refill(LZ4BlockInputStream.java:206)
	... 52 more

15992001
**** MultiplyDiablo run time: 527.928 secs
15992001
**** MultiplySpark run time: 555.789 secs
15992001
**** MultiplyDiablo run time: 525.625 secs
comet-22-13.ibnet: stopping org.apache.spark.deploy.worker.Worker
comet-27-56.ibnet: stopping org.apache.spark.deploy.worker.Worker
comet-27-53.ibnet: stopping org.apache.spark.deploy.worker.Worker
comet-27-70.ibnet: stopping org.apache.spark.deploy.worker.Worker
comet-27-58.ibnet: stopping org.apache.spark.deploy.worker.Worker
comet-22-58.ibnet: stopping org.apache.spark.deploy.worker.Worker
comet-27-16.ibnet: stopping org.apache.spark.deploy.worker.Worker
comet-22-70.ibnet: stopping org.apache.spark.deploy.worker.Worker
comet-22-57.ibnet: stopping org.apache.spark.deploy.worker.Worker
comet-27-45.ibnet: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
Stopping namenodes on [comet-22-13.ibnet]
comet-22-13.ibnet: stopping namenode
comet-27-16.ibnet: stopping datanode
comet-27-70.ibnet: stopping datanode
comet-22-13.ibnet: stopping datanode
comet-27-56.ibnet: stopping datanode
comet-27-45.ibnet: stopping datanode
comet-22-58.ibnet: stopping datanode
comet-22-70.ibnet: stopping datanode
comet-27-53.ibnet: stopping datanode
comet-27-58.ibnet: stopping datanode
comet-22-57.ibnet: stopping datanode
Stopping secondary namenodes [comet-22-13.ibnet]
comet-22-13.ibnet: stopping secondarynamenode
Copying Hadoop logs back to /home/fegaras/cometcluster/logs...
‘/scratch/fegaras/31371759/logs’ -> ‘/home/fegaras/cometcluster/logs’
‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-13.sdsc.edu.out’ -> ‘/home/fegaras/cometcluster/logs/hadoop-fegaras-datanode-comet-22-13.sdsc.edu.out’
‘/scratch/fegaras/31371759/logs/SecurityAuth-fegaras.audit’ -> ‘/home/fegaras/cometcluster/logs/SecurityAuth-fegaras.audit’
‘/scratch/fegaras/31371759/logs/spark-fegaras-org.apache.spark.deploy.master.Master-1-comet-22-13.out’ -> ‘/home/fegaras/cometcluster/logs/spark-fegaras-org.apache.spark.deploy.master.Master-1-comet-22-13.out’
‘/scratch/fegaras/31371759/logs/hadoop-fegaras-secondarynamenode-comet-22-13.sdsc.edu.log’ -> ‘/home/fegaras/cometcluster/logs/hadoop-fegaras-secondarynamenode-comet-22-13.sdsc.edu.log’
‘/scratch/fegaras/31371759/logs/hadoop-fegaras-namenode-comet-22-13.sdsc.edu.out’ -> ‘/home/fegaras/cometcluster/logs/hadoop-fegaras-namenode-comet-22-13.sdsc.edu.out’
‘/scratch/fegaras/31371759/logs/hadoop-fegaras-namenode-comet-22-13.sdsc.edu.log’ -> ‘/home/fegaras/cometcluster/logs/hadoop-fegaras-namenode-comet-22-13.sdsc.edu.log’
‘/scratch/fegaras/31371759/logs/hadoop-fegaras-secondarynamenode-comet-22-13.sdsc.edu.out’ -> ‘/home/fegaras/cometcluster/logs/hadoop-fegaras-secondarynamenode-comet-22-13.sdsc.edu.out’
‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-13.sdsc.edu.log’ -> ‘/home/fegaras/cometcluster/logs/hadoop-fegaras-datanode-comet-22-13.sdsc.edu.log’
removed ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current/fsimage_0000000000000000012’
removed ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current/edits_0000000000000000013-0000000000000000014’
removed ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current/edits_0000000000000000003-0000000000000000004’
removed ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current/edits_0000000000000000005-0000000000000000006’
removed ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current/edits_0000000000000000011-0000000000000000012’
removed ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000002’
removed ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current/edits_0000000000000000009-0000000000000000010’
removed ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current/fsimage_0000000000000000014.md5’
removed ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current/fsimage_0000000000000000014’
removed ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current/VERSION’
removed ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current/edits_0000000000000000007-0000000000000000008’
removed ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current/fsimage_0000000000000000012.md5’
removed directory: ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary/current’
removed directory: ‘/scratch/fegaras/31371759/tmp/dfs/namesecondary’
removed directory: ‘/scratch/fegaras/31371759/tmp/dfs’
removed directory: ‘/scratch/fegaras/31371759/tmp’
removed ‘/scratch/fegaras/31371759/namenode_data/current/seen_txid’
removed ‘/scratch/fegaras/31371759/namenode_data/current/fsimage_0000000000000000012’
removed ‘/scratch/fegaras/31371759/namenode_data/current/fsimage_0000000000000000012.md5’
removed ‘/scratch/fegaras/31371759/namenode_data/current/edits_0000000000000000007-0000000000000000008’
removed ‘/scratch/fegaras/31371759/namenode_data/current/fsimage_0000000000000000014.md5’
removed ‘/scratch/fegaras/31371759/namenode_data/current/VERSION’
removed ‘/scratch/fegaras/31371759/namenode_data/current/fsimage_0000000000000000014’
removed ‘/scratch/fegaras/31371759/namenode_data/current/edits_inprogress_0000000000000000015’
removed ‘/scratch/fegaras/31371759/namenode_data/current/edits_0000000000000000013-0000000000000000014’
removed ‘/scratch/fegaras/31371759/namenode_data/current/edits_0000000000000000003-0000000000000000004’
removed ‘/scratch/fegaras/31371759/namenode_data/current/edits_0000000000000000011-0000000000000000012’
removed ‘/scratch/fegaras/31371759/namenode_data/current/edits_0000000000000000001-0000000000000000002’
removed ‘/scratch/fegaras/31371759/namenode_data/current/edits_0000000000000000009-0000000000000000010’
removed ‘/scratch/fegaras/31371759/namenode_data/current/edits_0000000000000000005-0000000000000000006’
removed directory: ‘/scratch/fegaras/31371759/namenode_data/current’
removed directory: ‘/scratch/fegaras/31371759/namenode_data’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/VERSION’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/dncp_block_verification.log.curr’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/tmp’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/rbw’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/finalized’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/dfsUsed’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data’
removed directory: ‘/scratch/fegaras/31371759/pids’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-13.sdsc.edu.out’
removed ‘/scratch/fegaras/31371759/logs/SecurityAuth-fegaras.audit’
removed ‘/scratch/fegaras/31371759/logs/spark-fegaras-org.apache.spark.deploy.master.Master-1-comet-22-13.out’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-secondarynamenode-comet-22-13.sdsc.edu.log’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-namenode-comet-22-13.sdsc.edu.out’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-namenode-comet-22-13.sdsc.edu.log’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-secondarynamenode-comet-22-13.sdsc.edu.out’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-13.sdsc.edu.log’
removed directory: ‘/scratch/fegaras/31371759/logs’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/finalized’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/rbw’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/dfsUsed’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/tmp’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/dncp_block_verification.log.curr’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data’
removed directory: ‘/scratch/fegaras/31371759/pids’
removed ‘/scratch/fegaras/31371759/logs/SecurityAuth-fegaras.audit’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-57.sdsc.edu.log’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-57.sdsc.edu.out’
removed directory: ‘/scratch/fegaras/31371759/logs’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/tmp’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/dfsUsed’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/rbw’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/finalized’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/dncp_block_verification.log.curr’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data’
removed directory: ‘/scratch/fegaras/31371759/pids’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-58.sdsc.edu.out’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-58.sdsc.edu.log’
removed ‘/scratch/fegaras/31371759/logs/SecurityAuth-fegaras.audit’
removed directory: ‘/scratch/fegaras/31371759/logs’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/VERSION’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/dncp_block_verification.log.curr’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/tmp’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/rbw’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/dfsUsed’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/finalized’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data’
removed directory: ‘/scratch/fegaras/31371759/pids’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-70.sdsc.edu.log’
removed ‘/scratch/fegaras/31371759/logs/SecurityAuth-fegaras.audit’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-22-70.sdsc.edu.out’
removed directory: ‘/scratch/fegaras/31371759/logs’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/dncp_block_verification.log.curr’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/finalized’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/dfsUsed’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/rbw’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/tmp’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data’
removed directory: ‘/scratch/fegaras/31371759/pids’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-16.sdsc.edu.out’
removed ‘/scratch/fegaras/31371759/logs/SecurityAuth-fegaras.audit’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-16.sdsc.edu.log’
removed directory: ‘/scratch/fegaras/31371759/logs’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/dncp_block_verification.log.curr’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/finalized’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/rbw’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/dfsUsed’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/tmp’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data’
removed directory: ‘/scratch/fegaras/31371759/pids’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-45.sdsc.edu.out’
removed ‘/scratch/fegaras/31371759/logs/SecurityAuth-fegaras.audit’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-45.sdsc.edu.log’
removed directory: ‘/scratch/fegaras/31371759/logs’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/tmp’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/dncp_block_verification.log.curr’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/rbw’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/VERSION’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/dfsUsed’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/finalized’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data’
removed directory: ‘/scratch/fegaras/31371759/pids’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-53.sdsc.edu.out’
removed ‘/scratch/fegaras/31371759/logs/SecurityAuth-fegaras.audit’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-53.sdsc.edu.log’
removed directory: ‘/scratch/fegaras/31371759/logs’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/tmp’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/dncp_block_verification.log.curr’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/finalized’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/rbw’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/dfsUsed’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data’
removed directory: ‘/scratch/fegaras/31371759/pids’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-56.sdsc.edu.log’
removed ‘/scratch/fegaras/31371759/logs/SecurityAuth-fegaras.audit’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-56.sdsc.edu.out’
removed directory: ‘/scratch/fegaras/31371759/logs’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/finalized’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/VERSION’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/dfsUsed’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/rbw’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/dncp_block_verification.log.curr’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/tmp’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/VERSION’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data’
removed directory: ‘/scratch/fegaras/31371759/pids’
removed ‘/scratch/fegaras/31371759/logs/SecurityAuth-fegaras.audit’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-58.sdsc.edu.log’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-58.sdsc.edu.out’
removed directory: ‘/scratch/fegaras/31371759/logs’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/VERSION’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/dncp_block_verification.log.curr’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/tmp’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/finalized’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/rbw’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/VERSION’
removed ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current/dfsUsed’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current/BP-669120096-198.202.113.122-1581013962538’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data/current’
removed directory: ‘/scratch/fegaras/31371759/hdfs_data’
removed directory: ‘/scratch/fegaras/31371759/pids’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-70.sdsc.edu.log’
removed ‘/scratch/fegaras/31371759/logs/SecurityAuth-fegaras.audit’
removed ‘/scratch/fegaras/31371759/logs/hadoop-fegaras-datanode-comet-27-70.sdsc.edu.out’
removed directory: ‘/scratch/fegaras/31371759/logs’
removed directory: ‘/tmp/Jetty_comet.22.13_ibnet_50090_secondary____.j84vyx/jsp’
removed directory: ‘/tmp/Jetty_comet.22.13_ibnet_50090_secondary____.j84vyx/.active’
removed directory: ‘/tmp/Jetty_comet.22.13_ibnet_50090_secondary____.j84vyx’
removed directory: ‘/tmp/Jetty_0_0_0_0_50075_datanode____hwtdwq/jsp’
removed directory: ‘/tmp/Jetty_0_0_0_0_50075_datanode____hwtdwq/.active’
removed directory: ‘/tmp/Jetty_0_0_0_0_50075_datanode____hwtdwq’
removed directory: ‘/tmp/Jetty_0_0_0_0_50070_hdfs____w2cu08/jsp’
removed directory: ‘/tmp/Jetty_0_0_0_0_50070_hdfs____w2cu08/.active’
removed directory: ‘/tmp/Jetty_0_0_0_0_50070_hdfs____w2cu08’
